#This file contains all of our code compiled using the stickytape module. 
#This was done not to obfuscate the code, but to get around the limitation of erebus of loading only one controller file, since our code has a large directory structure and many files. 
#If you want to examine our code and test it, please visit our github repository: https://github.com/iita-robotica/rescate_laberinto. There you will find all the individual files under the directory '/src'.
# Our code is free and open-source. We strongly encourage the sharing and distribution of this file and our github repository.


import contextlib as __stickytape_contextlib

@__stickytape_contextlib.contextmanager
def __stickytape_temporary_dir():
    import tempfile
    import shutil
    dir_path = tempfile.mkdtemp()
    try:
        yield dir_path
    finally:
        shutil.rmtree(dir_path)

with __stickytape_temporary_dir() as __stickytape_working_dir:
    def __stickytape_write_module(path, contents):
        import os, os.path

        def make_package(path):
            parts = path.split("/")
            partial_path = __stickytape_working_dir
            for part in parts:
                partial_path = os.path.join(partial_path, part)
                if not os.path.exists(partial_path):
                    os.mkdir(partial_path)
                    with open(os.path.join(partial_path, "__init__.py"), "wb") as f:
                        f.write(b"\n")

        make_package(os.path.dirname(path))

        full_path = os.path.join(__stickytape_working_dir, path)
        with open(full_path, "wb") as module_file:
            module_file.write(contents)

    import sys as __stickytape_sys
    __stickytape_sys.path.insert(0, __stickytape_working_dir)

    __stickytape_write_module('executor/executor.py', b'from data_structures.angle import Angle\n\nfrom flow_control.sequencer import Sequencer\nfrom flow_control.state_machine import StateMachine\nfrom flow_control.delay import DelayManager\n\nfrom executor.stuck_detector import StuckDetector\n\nfrom robot.robot import Robot\nfrom robot.drive_base import Criteria as RotationCriteria\n\nfrom mapping.mapper import Mapper\n\nfrom agent.agent import Agent\n\nfrom fixture_detection.fixture_clasification import FixtureClasiffier\n\nfrom final_matrix_creation.final_matrix_creator import FinalMatrixCreator\n\nfrom flags import SHOW_DEBUG, DO_SLOW_DOWN, SLOW_DOWN_S, DO_SAVE_FIXTURE_DEBUG, SAVE_FIXTURE_DEBUG_DIR\n\nimport time\n\nimport cv2 as cv\n\nclass Executor:\n    def __init__(self, mapper: Mapper, robot: Robot) -> None:\n        self.agent = Agent(mapper)\n        self.mapper = mapper # Maps everything\n        self.robot = robot # Low level movement and sensing\n\n        self.delay_manager = DelayManager()\n        self.stuck_detector = StuckDetector() # Detects if the wheels of the robot are moving or not\n\n        self.state_machine = StateMachine("init") # Manages states\n        self.state_machine.create_state("init", self.state_init, {"explore",}) # This state initializes and calibrates the robot\n        self.state_machine.create_state("explore", self.state_explore, {"end", "report_fixture", "send_map"}) # This state follows the position returned by the agent\n        self.state_machine.create_state("end", self.state_end)\n        #self.state_machine.create_state("detect_fixtures", self.state_detect_fixtures, {"explore", "report_fixture"})\n        self.state_machine.create_state("report_fixture", self.state_report_fixture, {"explore", "send_map"})\n        self.state_machine.create_state("send_map", self.state_send_map, {"explore", "end"})\n\n        self.sequencer = Sequencer(reset_function=self.delay_manager.reset_delay) # Allows for asynchronous programming\n\n        self.fixture_detector = FixtureClasiffier()\n\n        self.final_matrix_creator = FinalMatrixCreator(mapper.tile_size, mapper.pixel_grid.resolution)\n        \n        # Flags\n        self.mapping_enabled = False\n        self.victim_reporting_enabled = False\n\n        # Sequential functions used frequently\n        self.seq_print =           self.sequencer.make_simple_event( print)\n        self.seq_move_wheels =     self.sequencer.make_simple_event( self.robot.move_wheels)\n\n        self.seq_rotate_to_angle = self.sequencer.make_complex_event(self.robot.rotate_to_angle)\n        self.seq_rotate_slowly_to_angle = self.sequencer.make_complex_event(self.robot.rotate_slowly_to_angle)\n        self.seq_move_to_coords =  self.sequencer.make_complex_event(self.robot.move_to_coords)\n        self.seq_delay_seconds =   self.sequencer.make_complex_event(self.delay_manager.delay_seconds)\n\n        self.letter_to_report = None\n        self.report_orientation = Angle(0)\n\n        self.max_time_in_run = 8 * 60\n\n        self.robot.set_start_time()\n\n    def run(self):\n        """Advances the simulation, updates all components and executes the state machine."""\n        \n        while self.robot.do_loop():\n            self.robot.update() # Updates robot position and rotation, sensor positions and values, etc.\n\n            self.delay_manager.update(self.robot.time)\n            self.stuck_detector.update(self.robot.position,\n                                       self.robot.previous_position,\n                                       self.robot.drive_base.get_wheel_direction())\n            \n            self.do_mapping()\n\n            self.check_map_sending()\n\n            self.state_machine.run()\n\n            #self.final_matrix_creator.pixel_grid_to_final_grid(self.mapper.pixel_grid, self.mapper.start_position)\n\n            if DO_SLOW_DOWN:\n                time.sleep(SLOW_DOWN_S)\n\n\n            #final_matrix = self.final_matrix_creator.pixel_grid_to_final_grid(self.mapper.pixel_grid, self.mapper.start_position)\n\n            #print(final_matrix)\n\n            #print("state:", self.state_machine.state)\n            \n    def do_mapping(self):\n        """Updates the mapper is mapping is enabled."""\n\n        if self.mapping_enabled:\n                # Floor and lidar mapping\n                self.mapper.update(self.robot.get_point_cloud(), \n                                   self.robot.get_out_of_bounds_point_cloud(),\n                                   self.robot.get_lidar_detections(),\n                                   self.robot.get_camera_images(), \n                                   self.robot.position,\n                                   self.robot.orientation,\n                                   self.robot.time)\n                \n    def check_map_sending(self):\n        if self.robot.time > self.max_time_in_run - 2:\n            print(self.robot.time / 60)\n            self.state_machine.change_state("send_map")\n\n    # STATES\n    def state_init(self, change_state_function):\n        """Initializes and calibrates the robot."""\n\n        self.sequencer.start_sequence() # Starts the sequence\n        self.seq_delay_seconds(0.5)\n\n        self.sequencer.simple_event(self.calibrate_position_offsets) # Calculates offsets in the robot position, in case it doesn\'t start perfectly centerd\n        \n        self.sequencer.simple_event(self.mapper.register_start, self.robot.position) # Informs the mapping components of the starting position of the robot\n        \n        self.seq_calibrate_robot_rotation() # Calibrates the rotation of the robot using the gps\n\n        # Starts mapping walls\n        if self.sequencer.simple_event():\n            self.mapping_enabled = True\n            self.victim_reporting_enabled = True\n\n        self.seq_delay_seconds(0.5)\n        self.sequencer.complex_event(self.robot.rotate_to_angle, angle=Angle(90, Angle.DEGREES), direction=RotationCriteria.LEFT)\n        self.sequencer.complex_event(self.robot.rotate_to_angle, angle=Angle(180, Angle.DEGREES), direction=RotationCriteria.LEFT)\n        self.seq_delay_seconds(0.5)\n\n\n        self.sequencer.simple_event(change_state_function, "explore") # Changes state\n        self.sequencer.seq_reset_sequence() # Resets the sequence\n\n\n    def state_explore(self, change_state_function):\n        """Follows the instructions of the agent."""\n\n        self.sequencer.start_sequence() # Starts the sequence\n\n        if SHOW_DEBUG and self.agent_changed():\n            print("CHANGING AGENT")\n\n        self.agent.update()\n\n        self.seq_move_to_coords(self.agent.get_target_position())\n      \n        self.sequencer.seq_reset_sequence() # Resets the sequence but doesn\'t change state, so it starts all over again.\n\n        if SHOW_DEBUG:\n            print("rotation:", self.robot.orientation)\n            print("position:", self.robot.position)\n        \n        if self.agent.do_end():\n            self.state_machine.change_state("end")\n\n        cam_images = self.robot.get_camera_images()\n        if self.victim_reporting_enabled and cam_images is not None and not self.mapper.has_detected_victim_from_position():\n            for cam_image in cam_images:\n                fixtures = self.fixture_detector.find_fixtures(cam_image.image)   \n                if len(fixtures):\n                    self.letter_to_report = self.fixture_detector.classify_fixture(fixtures[0])\n                    self.report_orientation = cam_image.data.horizontal_orientation\n\n                    #TODO Sacar en codigo final\n                    if DO_SAVE_FIXTURE_DEBUG:\n                        cv.imwrite(f"{SAVE_FIXTURE_DEBUG_DIR}/{str(time.time()).rjust(50)}-{self.letter_to_report}-{self.robot.position}.png", cam_image.image)\n                    change_state_function("report_fixture")\n                    self.sequencer.reset_sequence() # Resets the sequence\n                    break\n\n    def state_end(self, change_state_function):\n        final_matrix = self.final_matrix_creator.pixel_grid_to_final_grid(self.mapper.pixel_grid, self.mapper.start_position)\n        self.robot.comunicator.send_map(final_matrix)\n        self.robot.comunicator.send_end_of_play()\n\n        \n\n    def state_send_map(self, change_state_function):\n        final_matrix = self.final_matrix_creator.pixel_grid_to_final_grid(self.mapper.pixel_grid, self.mapper.start_position)\n        self.robot.comunicator.send_map(final_matrix)\n        change_state_function("explore")\n\n    def state_report_fixture(self, change_state_function):\n        self.sequencer.start_sequence()\n        self.seq_print("entered_report_fixture")\n        self.seq_move_wheels(0, 0)\n\n        if self.letter_to_report is not None:\n            self.report_orientation.normalize()\n            self.seq_rotate_to_angle(self.report_orientation.degrees)\n            self.seq_move_wheels(0.6, 0.6)\n            self.seq_delay_seconds(0.2)\n            self.seq_move_wheels(0, 0)\n            self.seq_delay_seconds(2)\n\n        if self.sequencer.simple_event():\n            if self.letter_to_report is not None:\n                print("sending letter:", self.letter_to_report)\n                self.robot.comunicator.send_victim(self.robot.raw_position, self.letter_to_report)\n        \n        if self.sequencer.simple_event():\n            self.letter_to_report = None\n            self.mapper.fixture_mapper.map_detected_fixture(self.robot.position)\n\n        self.sequencer.simple_event(change_state_function, "explore")\n        self.sequencer.seq_reset_sequence() # Resets the sequence\n\n    def calibrate_position_offsets(self):\n        """Calculates offsets in the robot position, in case it doesn\'t start perfectly centerd."""\n        print("robot_position:", self.robot.position)\n        self.robot.position_offsets = self.robot.position % (self.mapper.quarter_tile_size * 2)\n        print("positionOffsets: ", self.robot.position_offsets)\n        \n\n    def seq_calibrate_robot_rotation(self):\n        """ Calibrates the robot rotation using the gps."""\n\n        if self.sequencer.simple_event():\n            self.robot.auto_decide_orientation_sensor = False\n        self.seq_move_wheels(-1, -1)\n        self.seq_delay_seconds(0.1)\n        if self.sequencer.simple_event(): \n            self.robot.orientation_sensor = self.robot.GPS\n        self.seq_move_wheels(1, 1)\n        self.seq_delay_seconds(0.1)\n        if self.sequencer.simple_event(): \n            self.robot.orientation_sensor = self.robot.GYROSCOPE\n        self.seq_delay_seconds(0.1)\n        self.seq_move_wheels(0, 0)\n        self.seq_move_wheels(-1, -1)\n        self.seq_delay_seconds(0.1)\n        self.seq_move_wheels(0, 0)\n        if self.sequencer.simple_event():\n            self.robot.auto_decide_orientation_sensor = True\n\n    def agent_changed(self):\n        return self.current_agent != self.previous_agent\n\n            \n\n\n\n\n\n    \n\n\n')
    __stickytape_write_module('data_structures/angle.py', b'import math\nfrom copy import copy\n\nclass Angle:\n    RADIANS = 0\n    DEGREES = 1\n    def __init__(self, value, unit=RADIANS):\n        if unit == self.RADIANS:\n            self.__radians = float(value)\n        else:\n            self.degrees = value\n\n    @property\n    def radians(self, value):\n        self.__radians = value\n\n    @radians.getter\n    def radians(self):\n        return float(self.__radians)\n    \n    @property\n    def degrees(self):\n        return float(self.__radians * 180 / math.pi)\n    \n    @degrees.setter\n    def degrees(self, value):\n        self.__radians = value * math.pi / 180\n\n    def normalize(self):\n        self.__radians %= 2 * math.pi\n\n        if self.__radians < 0:\n            self.__radians += 2 + math.pi\n    \n    def get_absolute_distance_to(self, angle):\n        angle = copy(angle)\n        angle.normalize()\n        min_ang = min(self.radians, angle.radians)\n        max_ang = max(self.radians, angle.radians)\n\n        clockwise_distance = max_ang - min_ang\n        counterclockwise_distance = (math.pi * 2 + min_ang) - max_ang\n\n        return Angle(min(clockwise_distance, counterclockwise_distance))\n    \n    def get_distance_to(self, angle):\n        val = self.get_absolute_distance_to(angle)\n\n        angle_difference = self - angle\n\n        if 180 > angle_difference.degrees > 0 or angle_difference.degrees < -180:\n            return val\n        else:\n            return val * -1\n            \n        \n    \n    def __str__(self):\n        return str(self.degrees)\n    \n    def __repr__(self):\n        return str(self.degrees)\n    \n    def __add__(self, other):\n        if isinstance(other, Angle):\n            return Angle(self.radians + other.radians)\n        return Angle(self.radians + other)\n    \n    def __radd__(self, other):\n        return self.__add__(other)\n    \n    def __sub__(self, other):\n        if isinstance(other, Angle):\n            return Angle(self.radians - other.radians)\n        return Angle(self.radians - other)\n    \n    def __rsub__(self, other):\n        return self.__sub__(other)\n    \n    def __mul__(self, other):\n        if isinstance(other, Angle):\n            return Angle(self.radians * other.radians)\n        return Angle(self.radians * other)\n    \n    def __rmul__(self, other):\n        return self.__mul__(other)\n    \n    def __truediv__(self, other):\n        if isinstance(other, Angle):\n            return Angle(self.radians / other.radians)\n        return Angle(self.radians / other)\n    \n    def __rtruediv__(self, other):\n        return self.__truediv__(other)\n    \n    def __floordiv__(self, other):\n        if isinstance(other, Angle):\n            return Angle(self.radians // other.radians)\n        return Angle(self.radians // other)\n    \n    def __rfloordiv__(self, other):\n        return self.__floordiv__(other)\n    \n    def __mod__(self, other):\n        if isinstance(other, Angle):\n            return Angle(self.radians % other.radians)\n        return Angle(self.radians % other)\n    \n    def __rmod__(self, other):\n        return self.__mod__(other)\n    \n    def __divmod__(self, other):\n        if isinstance(other, Angle):\n            return (Angle(self.radians // other.radians), Angle(self.radians % other.radians))\n        return (Angle(self.radians // other), Angle(self.radians % other))\n    \n    def __rdivmod__(self, other):\n        return self.__divmod__(other)\n    \n    def __pow__(self, other):\n        if isinstance(other, Angle):\n            return Angle(self.radians ** other.radians)\n        return Angle(self.radians ** other)\n    \n    def __rpow__(self, other):\n        return self.__pow__(other)\n    \n    def __neg__(self):\n        return Angle(-self.radians)\n\n    def __pos__(self):\n        return self\n\n    def __abs__(self):\n        return Angle(abs(self.radians))\n\n    def __eq__(self, other):\n        if isinstance(other, Angle):\n            return self.radians == other.radians\n        return self.radians == other\n\n    def __ne__(self, other):\n        if isinstance(other, Angle):\n            return self.radians != other.radians\n        return self.radians != other\n\n    def __lt__(self, other):\n        if isinstance(other, Angle):\n            return self.radians < other.radians\n        return self.radians < other\n\n    def __le__(self, other):\n        if isinstance(other, Angle):\n            return self.radians <= other.radians\n        return self.radians <= other\n\n    def __gt__(self, other):\n        if isinstance(other, Angle):\n            return self.radians > other.radians\n        return self.radians > other\n\n    def __ge__(self, other):\n        if isinstance(other, Angle):\n            return self.radians >= other.radians\n        return self.radians >= other\n\n    def __int__(self):\n        return int(self.radians)\n\n    def __float__(self):\n        return float(self.radians)\n\n    def __complex__(self):\n        return complex(self.radians)\n    \n    def __round__(self, ndigits=None):\n        return Angle(round(self.__radians, ndigits))\n    \n')
    __stickytape_write_module('flow_control/sequencer.py', b'from flags import SHOW_DEBUG\n\n\n\nclass Sequencer:\n    """\n    Makes it possible to run arbitrary code sequentially without interrupting other code that must run continuoulsy.\n    For example, one can make the robot execute a series of pre-programmed functions with delays and so on, without interrupting\n    a sensor that must run continously. \n    This functions basically as an alternative to multithreading or multiprocessing.\n    """\n    def __init__(self, reset_function=None):\n        self.line_identifier = 0\n        self.line_pointer = 1\n        self.done = False\n        self.reset_function = reset_function\n\n    def reset_sequence(self):\n        """\n        Resets the sequence and makes it start from the first event.\n        """\n        if self.reset_function is not None:\n            self.reset_function()\n        self.line_pointer = 1\n        if SHOW_DEBUG:\n            print("----------------")\n            print("reseting sequence")\n            print("----------------")\n\n    def seq_reset_sequence(self):\n        if self.check():\n            self.reset_sequence()\n            \n            return True\n        return False\n\n    def start_sequence(self):\n        """\n        Starts the sequence. This must be at the start of any sequence of events.\n        """\n        self.line_identifier = 0\n        self.done = False\n\n\n    def check(self):\n        """\n        Returns if the line pointer and identifier match and increases the identifier.\n        Must be included at the end of any sequential function.\n        """\n        self.done = False\n        self.line_identifier += 1\n        return self.line_identifier == self.line_pointer\n\n    def next_seq(self):\n        """\n        Changes to the next event.\n        """\n        self.line_pointer += 1\n        self.done = True\n\n    def seq_done(self):\n        """\n        returns if the sequence has reached its end\n        """\n        return self.done\n\n    def simple_event(self, function=None, *args, **kwargs):\n        """\n        Can be used to make a function sequential or used with an if statement to make a code block sequential.\n        """\n        if self.check():\n            if function is not None:\n                function(*args, **kwargs)\n            self.next_seq()\n            return True\n        return False\n\n    def complex_event(self, function, *args, **kwargs):\n        """\n        Can be used to make a function sequential. The function inputted must return True when it ends\n        """\n        if self.check():\n            if function(*args, **kwargs):\n                self.next_seq()\n                return True\n        return False\n    \n    def make_simple_event(self, function):\n        """\n        When inpuuted any function it returns a sequential version of it that can be used in a sequence.\n        """\n        def event(*args, **kwargs):\n            if self.check():\n                function(*args, **kwargs)\n                self.next_seq()\n                return True\n            return False\n        return event\n\n    def make_complex_event(self, function):\n        """\n        When inputted a function that returns True when it ends returns a sequential version of it that can be used in a sequence.\n        """\n        def event(*args, **kwargs):\n            if self.check():\n                if function(*args, **kwargs):\n                    self.next_seq()\n                    return True\n            return False\n        return event\n')
    __stickytape_write_module('flags.py', b'\nSHOW_FIXTURE_DEBUG = False\nSHOW_DEBUG = False\n\nSHOW_GRANULAR_NAVIGATION_GRID = False\nSHOW_PATHFINDING_DEBUG = False\nSHOW_BEST_POSITION_FINDER_DEBUG = False\n\nSHOW_MAP_AT_END = False\n\nDO_WAIT_KEY = False\n\nDO_SLOW_DOWN = False\nSLOW_DOWN_S = 0.032\n\n\nDO_SAVE_FIXTURE_DEBUG = False\nSAVE_FIXTURE_DEBUG_DIR = "/home/iitaadmin/simulated_rescue_maze/debug_imgs"')
    __stickytape_write_module('flow_control/state_machine.py', b'from typing import Callable\n\nclass StateMachine:\n    """\n    A simple state machine.\n    """\n    def __init__(self, initial_state, function_on_change_state=lambda:None):\n        self.state = initial_state\n        self.current_function = lambda:None\n\n        self.change_state_function = function_on_change_state\n\n        self.state_functions = {}\n        self.allowed_state_changes = {}\n        self.possible_states = set()\n\n    def create_state(self, name: str, function: Callable, possible_changes = set()):\n        if name in self.possible_states:\n            raise ValueError("Failed to create new state. State already exists.")\n        self.possible_states.add(name)\n        self.state_functions[name] = function\n        self.allowed_state_changes[name] = possible_changes\n        if name == self.state:\n            self.current_function = self.state_functions[self.state]\n\n    def change_state(self, new_state):\n        """Sets the state the specified value."""\n        if new_state not in self.possible_states:\n            raise ValueError("Can\'t change state. New state doesn\'t exist.")\n        \n        if new_state in self.allowed_state_changes[self.state]:\n            self.change_state_function()\n            self.state = new_state\n            self.current_function = self.state_functions[self.state]\n\n        else:\n            print(f"WARNING: Can\'t change to state {new_state}. New state is not in the possible changes for {self.state}.")\n        return True\n\n    def check_state(self, state):\n        """Checks if the state corresponds the specified value."""\n        return self.state == state\n    \n    def run(self):\n        return self.current_function(self.change_state)')
    __stickytape_write_module('flow_control/delay.py', b'from flags import SHOW_DEBUG\n\n\nclass DelayManager:\n    def __init__(self) -> None:\n        self.time = 0\n        self.delay_first_time = True\n        self.delay_start = 0\n    \n    def update(self, time):\n        self.time = time\n\n    def delay_seconds(self, delay):\n            if SHOW_DEBUG:\n                print("Current delay: ", delay)\n            if self.delay_first_time:\n                self.delay_start = self.time\n                self.delay_first_time = False\n            else:\n                if self.time - self.delay_start >= delay:\n                    \n                    self.delay_first_time = True\n                    return True\n            return False\n    \n    def reset_delay(self):\n         self.delay_first_time = True')
    __stickytape_write_module('executor/stuck_detector.py', b'from data_structures.vectors import Position2D\n\nclass StuckDetector:\n    """Checks if the robot is rotating the wheels but not actually moving."""\n    def __init__(self) -> None:\n        self.stuck_counter = 0\n\n        self.stuck_threshold = 50\n        self.minimum_distance_traveled = 0.00001\n\n        self.__position = Position2D(0, 0)\n        self.__previous_position = Position2D(0, 0)\n        self.__wheel_direction = 0\n\n    def update(self, position, previous_position, wheel_direction):\n        self.__wheel_direction = wheel_direction\n        self.__position = position\n        self.__previous_position = previous_position\n\n        # Check if the robot is not moving\n        if self.__is_stuck_this_step():\n            self.stuck_counter += 1\n        else:\n            self.stuck_counter = 0    \n\n    def is_stuck(self):\n        return self.stuck_counter > self.stuck_threshold\n    \n    def __is_stuck_this_step(self):\n        distance_traveled = self.__position.get_distance_to(self.__previous_position)\n        is_rotating_wheels = self.__wheel_direction > 0\n        return is_rotating_wheels and distance_traveled < self.minimum_distance_traveled\n\n\n   ')
    __stickytape_write_module('data_structures/vectors.py', b'import math\nimport numpy as np\n\nfrom data_structures.angle import Angle\n\nclass Position2D:\n    def __init__(self, *args, **kwargs):\n        """\n        Takes either two values or an iterable with at least two indices.\n        """\n        if len(args) == 0:\n            self.x = None\n            self.y = None\n        elif len(args) == 1:\n            self.x = args[0][0]\n            self.y = args[0][1]\n        elif len(args) == 2:\n            self.x = args[0]\n            self.y = args[1]\n        else:\n            raise TypeError()\n\n    \n    def __iter__(self):\n        yield self.x\n        yield self.y\n    \n    def __array__(self, *args, **kwargs):\n        return np.array([self.x, self.y], *args, **kwargs)\n        \n    def __repr__(self):\n        return f"Position2D({self.x}, {self.y})"\n    \n    def __eq__(self, other):\n        if isinstance(other, Position2D):\n            return self.x == other.x and self.y == other.y\n        else:\n            return False\n    \n    def __add__(self, other):\n        if isinstance(other, Position2D):\n            return Position2D(self.x + other.x, self.y + other.y)\n        else:\n            return Position2D(self.x + other, self.y + other)\n    \n    def __radd__(self, other):\n        return self + other\n    \n    def __sub__(self, other):\n        if isinstance(other, Position2D):\n            return Position2D(self.x - other.x, self.y - other.y)\n        else:\n            return Position2D(self.x - other, self.y - other)\n    \n    def __rsub__(self, other):\n        return -self + other\n    \n    def __mul__(self, other):\n        if isinstance(other, Position2D):\n            return Position2D(self.x * other.x, self.y * other.y)\n        else:\n            return Position2D(self.x * other, self.y * other)\n    \n    def __rmul__(self, other):\n        return self * other\n    \n    def __truediv__(self, other):\n        if isinstance(other, Position2D):\n            return Position2D(self.x / other.x, self.y / other.y)\n        else:\n            return Position2D(self.x / other, self.y / other)\n    \n    def __rtruediv__(self, other):\n        return Position2D(other / self.x, other / self.y)\n    \n    def __floordiv__(self, other):\n        if isinstance(other, Position2D):\n            return Position2D(self.x // other.x, self.y // other.y)\n        return Position2D(self.x // other, self.y // other)\n    \n    def __rfloordiv__(self, other):\n        return self.__floordiv__(other)\n    \n    def __mod__(self, other):\n        if isinstance(other, Position2D):\n            return Position2D(self.x % other.x, self.y % other.y)\n        else:\n            return Position2D(self.x % other, self.y % other)\n    \n    def __rmod__(self, other):\n        return self.__mod__(other)\n    \n    def __divmod__(self, other):\n        return self.__floordiv__(other), self.__mod__(other)\n    \n    \n    def __rdivmod__(self, other):\n        return self.__divmod__(other)\n    \n    def __pow__(self, other):\n        if isinstance(other, Position2D):\n            return Position2D(self.x ** other.x, self.y ** other.y)\n        else:\n            return Position2D(self.x ** other, self.y ** other)\n    \n    def __rpow__(self, other):\n        return self.__pow__(other)\n    \n    def __neg__(self):\n        return Position2D(-self.x, -self.y)\n    \n    def __pos__(self):\n        return Position2D(self.x, self.y)\n    \n    def __abs__(self):\n        return math.sqrt(self.x ** 2 + self.y ** 2)\n    \n    def __getitem__(self, index):\n        if index == 0:\n            return self.x\n        elif index == 1:\n            return self.y\n        else:\n            raise IndexError("Vector index out of range")\n    \n    def __setitem__(self, index, value):\n        if index == 0:\n            self.x = value\n        elif index == 1:\n            self.y = value\n        else:\n            raise IndexError("Vector index out of range")\n        \n    def astype(self, dtype: type):\n        return self.apply_to_all(dtype)\n    \n    def apply_to_all(self, function):\n        return Position2D(function(self.x), function(self.y))\n    \n    def get_distance_to(self, other):\n        return abs(self - other)\n    \n    def get_angle_to(self, other):\n        delta = self - other \n        result = Angle(math.atan2(delta.x, delta.y)) + Angle(180, Angle.DEGREES)\n        result.normalize()\n        return result\n    \n\n    def to_vector(self):\n        m = Position2D(0, 0).get_distance_to(self)\n        a = Position2D(0, 0).get_angle_to(self)\n        return Vector2D(a, m)\n       \nclass Vector2D:\n    def __init__(self, direction:Angle=None, magnitude=None):\n        self.direction = direction\n        self.magnitude = magnitude\n        \n    def __repr__(self):\n        return f"Vector2D(direction={self.direction}, magnitude={self.magnitude})"\n    \n    def __eq__(self, other):\n        if isinstance(other, Vector2D):\n            return self.direction == other.direction and self.magnitude == other.magnitude\n        else:\n            return False\n    \n    def __add__(self, other):\n        if isinstance(other, Vector2D):\n            return Vector2D(self.direction + other.direction, self.magnitude + other.magnitude)\n        else:\n            raise TypeError("Argument must be of type Vector2D")\n    \n    def __radd__(self, other):\n        return self + other\n    \n    def __sub__(self, other):\n        if isinstance(other, Vector2D):\n            return Vector2D(self.direction - other.direction, self.magnitude - other.y)\n        else:\n            raise TypeError("Argument must be of type Vector2D")\n    \n    def __rsub__(self, other):\n        return -self + other\n    \n    \n    def __neg__(self):\n        return Vector2D(-self.direction, -self.magnitude)\n    \n    def __pos__(self):\n        return Vector2D(self.direction, self.magnitude)\n    \n    \n    def to_position(self):\n        y = float(self.magnitude * math.cos(self.direction.radians))\n        x = float(self.magnitude * math.sin(self.direction.radians))\n        return Position2D(x, y)\n    ')
    __stickytape_write_module('robot/robot.py', b'from controller import Robot as WebotsRobot\n\nfrom flow_control.step_counter import StepCounter\n\nfrom data_structures.angle import Angle\nfrom data_structures.vectors import Position2D, Vector2D\n\n# Devices\nfrom robot.devices.wheel import Wheel\nfrom robot.devices.camera import Camera\nfrom robot.devices.lidar import Lidar\nfrom robot.devices.gps import Gps\nfrom robot.devices.gyroscope import Gyroscope\nfrom robot.devices.comunicator import Comunicator\n\nfrom robot.pose_manager import PoseManager\n\nfrom robot.drive_base import DriveBase, Criteria\n\nimport cv2 as cv\n\n\nclass Robot:\n    """\n    Abstraction layer for the webots robot. In charge of low level movement and sensing.\n    """\n    def __init__(self, time_step):\n        self.time_step = time_step\n        self.__start_time = 0\n        self.__time = 0\n\n        self.diameter = 0.074 # Robot diameter in meters\n        \n        self.robot = WebotsRobot() # Robot object provided by webots\n\n        self.gps = Gps(self.robot.getDevice("gps"), self.time_step)\n        self.gyroscope = Gyroscope(self.robot.getDevice("gyro"), 1, self.time_step)\n        \n        self.pose_manager = PoseManager(self.gps, self.gyroscope) # This manages position and orientation\n\n        # LIDAR\n        lidar_interval = 6\n        self.lidar = Lidar(webots_device = self.robot.getDevice("lidar"), \n                           time_step = self.time_step * lidar_interval, \n                           step_counter = StepCounter(lidar_interval),\n                           layers_used=(2,))\n        \n        # Cameras\n        self.camera_distance_from_center = 0.0310\n        camera_interval = 3\n        self.center_camera = Camera(webots_device = self.robot.getDevice("camera1"),\n                                    time_step = self.time_step * camera_interval,\n                                    step_counter = StepCounter(camera_interval),\n                                    orientation=Angle(0, Angle.DEGREES),\n                                    distance_from_center=self.camera_distance_from_center)\n        \n        self.right_camera = Camera(webots_device = self.robot.getDevice("camera2"),\n                                   time_step = self.time_step * camera_interval,\n                                   step_counter = StepCounter(camera_interval),\n                                   orientation=Angle(270, Angle.DEGREES),\n                                   distance_from_center=self.camera_distance_from_center)\n        \n        self.left_camera = Camera(webots_device = self.robot.getDevice("camera3"), \n                                  time_step = self.time_step * camera_interval, \n                                  step_counter = StepCounter(camera_interval),\n                                  orientation=Angle(90, Angle.DEGREES),\n                                  distance_from_center=self.camera_distance_from_center,\n                                  rotate180=True)\n        \n        # Comunicator (Emmiter and reciever)\n        self.comunicator = Comunicator(self.robot.getDevice("emitter"), self.robot.getDevice("receiver"), self.time_step)\n        \n        # Low level movement\n        max_wheel_speed = 6.28\n        self.drive_base = DriveBase(left_wheel = Wheel(self.robot.getDevice("wheel1 motor"), max_wheel_speed), \n                                    right_wheel = Wheel(self.robot.getDevice("wheel2 motor"), max_wheel_speed),\n                                    max_wheel_velocity = max_wheel_speed)\n\n    def update(self):\n        """Must run every TimeStep"""\n        # Update current time\n        self.__time = self.robot.getTime()\n\n        # Update pose manager (Position and rotation)\n        self.pose_manager.update(wheel_direction=self.drive_base.get_wheel_direction())\n\n        # Update drive base\n        self.drive_base.orientation = self.orientation\n        self.drive_base.position = self.position\n\n        # Lidar update\n        self.lidar.set_orientation(self.orientation)\n        self.lidar.update()\n\n        # Camera update\n        self.right_camera.update(self.orientation)\n        self.left_camera.update(self.orientation)\n        self.center_camera.update(self.orientation)\n\n    def do_loop(self):\n        """Advances the simulation by one step and returns True if the simulation is running."""\n        return self.robot.step(self.time_step) != -1\n    \n    def set_start_time(self):\n        self.__start_time = self.robot.getTime()\n\n    @property\n    def time(self):\n        return self.__time - self.__start_time\n\n    # Wrappers for DriveBase\n    @property\n    def max_wheel_speed(self):\n        return self.drive_base.max_wheel_velocity\n\n    def move_wheels(self, left_ratio, right_ratio):\n        self.drive_base.move_wheels(left_ratio, right_ratio)\n\n    def rotate_to_angle(self, angle, direction=Criteria.CLOSEST):\n        return self.drive_base.rotate_to_angle(Angle(angle, Angle.DEGREES), direction)\n    \n    def rotate_slowly_to_angle(self, angle, direction=Criteria.CLOSEST):\n        return self.drive_base.rotate_slowly_to_angle(angle, direction)\n        \n\n    def move_to_coords(self, targetPos):\n        return self.drive_base.move_to_position(Position2D(targetPos[0], targetPos[1]))\n    \n    # Wrappers for lidar\n    @property\n    def point_is_close(self) -> bool:\n        return self.lidar.is_point_close\n\n    def get_point_cloud(self):\n        return self.lidar.get_point_cloud()\n\n    def get_out_of_bounds_point_cloud(self):\n        return self.lidar.get_out_of_bounds_point_cloud()\n    \n\n    def get_lidar_detections(self):\n        return self.lidar.get_detections()\n    \n    # Wrapper for cameras\n    def get_camera_images(self):\n        if self.center_camera.step_counter.check():\n            return [self.right_camera.get_image(), \n                    self.center_camera.get_image(), \n                    self.left_camera.get_image()]\n        \n    def get_last_camera_images(self):\n        return [self.right_camera.get_last_image(),\n                self.center_camera.get_last_image(),\n                self.left_camera.get_last_image()]\n        \n    # Wrappers for pose\n    @property\n    def position(self):\n        return self.pose_manager.position\n    \n    @property\n    def raw_position(self):\n        return self.pose_manager.raw_position\n    \n    @property\n    def previous_position(self):\n        return self.pose_manager.previous_position\n    \n    @property\n    def position_offsets(self):\n        return self.pose_manager.position_offsets\n    \n    @position_offsets.setter\n    def position_offsets(self, value):\n        self.pose_manager.position_offsets = value\n    \n    @property\n    def orientation(self):\n        return self.pose_manager.orientation\n    \n    @property\n    def previous_orientation(self):\n        return self.pose_manager.previous_orientation\n    \n    @property\n    def auto_decide_orientation_sensor(self):\n        return self.pose_manager.automatically_decide_orientation_sensor\n    \n    @auto_decide_orientation_sensor.setter\n    def auto_decide_orientation_sensor(self, value):\n        self.pose_manager.automatically_decide_orientation_sensor = value\n\n    @property\n    def orientation_sensor(self):\n        return self.pose_manager.orientation_sensor\n    \n    @orientation_sensor.setter\n    def orientation_sensor(self, value):\n        self.pose_manager.orientation_sensor = value\n    \n    @property\n    def GPS(self):\n        return PoseManager.GPS\n    \n    @property\n    def GYROSCOPE(self):\n        return PoseManager.GYROSCOPE\n    ')
    __stickytape_write_module('flow_control/step_counter.py', b'class StepCounter:\n    """\n    Allows to execute actions every n number of timesteps. This can be useful for performance, as it enables the program\n    to execute taxing tasks sparsely while not interrupting actions that must run constantly.\n    """\n\n    def __init__(self, interval):\n        self.__current_step = 0\n        self.interval = interval\n\n    def increase(self):\n        self.__current_step += 1\n        if self.__current_step == self.interval:\n            self.__current_step = 0\n    \n    def check(self):\n        return self.__current_step == 0')
    __stickytape_write_module('robot/devices/wheel.py', b'# Controlls a wheel\nclass Wheel:\n    def __init__(self, wheel, maxVelocity):\n        self.maxVelocity = maxVelocity\n        self.wheel = wheel\n        self.velocity = 0\n        self.wheel.setPosition(float("inf"))\n        self.wheel.setVelocity(0)\n\n    # Moves the wheel at a ratio of the maximum speed (between 0 and 1)\n    def move(self, ratio):\n        if ratio > 1:\n            ratio = 1\n        elif ratio < -1:\n            ratio = -1\n        self.velocity = ratio * self.maxVelocity\n        self.wheel.setVelocity(self.velocity)')
    __stickytape_write_module('robot/devices/camera.py', b'import numpy as np\nfrom robot.devices.sensor import TimedSensor\nimport cv2 as cv\n\nfrom flow_control.step_counter import StepCounter\n\nfrom data_structures.angle import Angle\n\nfrom dataclasses import dataclass\n\nimport math\n\n@dataclass\nclass CameraData:\n    height: int\n    width: int\n    vertical_fov: Angle\n    horizontal_fov: Angle\n    relative_vertical_orientation: Angle\n    relative_horizontal_orientation: Angle\n    vertical_orientation: Angle\n    horizontal_orientation: Angle\n    distance_from_center: float\n\nclass CameraImage:\n    def __init__(self) -> None:\n        self.image: np.ndarray = None\n        self.data: CameraData = None\n\n# Captures images and processes them\nclass Camera(TimedSensor):\n    def __init__(self, webots_device, time_step, step_counter: StepCounter, orientation: Angle, distance_from_center: float, rotate180=False):\n        super().__init__(webots_device, time_step, step_counter)\n        self.rotate180 = rotate180\n        self.height = self.device.getHeight()\n        self.width = self.device.getWidth()\n        self.horizontal_fov = Angle(self.device.getFov())\n        self.vertical_fov = Angle(2 * math.atan(math.tan(self.horizontal_fov * 0.5) * (self.height / self.width)))\n        self.image = CameraImage()\n        \n        self.horizontal_orientation_in_robot = orientation\n        self.vertical_orientation_in_robot = Angle(0)\n\n        self.horizontal_orientation = orientation\n        self.vertical_orientation = Angle(0)\n        self.distance_from_center = distance_from_center\n\n    # Returns the camera image\n    def get_image(self):\n        if self.step_counter.check():\n            return self.image\n    \n    def get_last_image(self):\n        return self.image\n\n        \n    def get_data(self):\n        data = CameraData(self.height,\n                          self.width,\n                          self.vertical_fov,\n                          self.horizontal_fov,\n                          self.vertical_orientation_in_robot,\n                          self.horizontal_orientation_in_robot,\n                          self.vertical_orientation,\n                          self.horizontal_orientation,\n                          self.distance_from_center)\n        return data\n    \n    def update(self, robot_orientation: Angle):\n        super().update()\n\n        self.horizontal_orientation = self.horizontal_orientation_in_robot + robot_orientation\n        \n        # Do evey n steps\n        if self.step_counter.check():\n            # Extract image from buffer\n            image_data = self.device.getImage()\n            self.image.image = np.array(np.frombuffer(image_data, np.uint8).reshape((self.height, self.width, 4)))\n\n            if self.rotate180:\n                self.image.image = np.rot90(self.image.image, 2, (0, 1))\n\n            self.image.orientation = self.horizontal_orientation\n\n            self.image.data = self.get_data()\n\n            ')
    __stickytape_write_module('robot/devices/sensor.py', b'from abc import ABC, abstractmethod\n\nclass Sensor(ABC):\n    def __init__(self, webots_device, time_step):\n        self.time_step = time_step\n        self.device = webots_device\n        self.device.enable(time_step)\n\n    def update(self):\n        pass\n\nclass TimedSensor(Sensor):\n    def __init__(self, webots_device, time_step, step_counter):\n        super().__init__(webots_device, time_step)\n        self.step_counter = step_counter\n\n    def update(self):\n        self.step_counter.increase()\n')
    __stickytape_write_module('robot/devices/lidar.py', b'import math\n\nimport utilities\nfrom utilities import divide_into_chunks\n\nfrom robot.devices.sensor import TimedSensor\nfrom data_structures.angle import Angle\nfrom data_structures.vectors import Vector2D\n\n# Returns a point cloud of the detctions it makes\nclass Lidar(TimedSensor):\n    def __init__(self, webots_device, time_step, step_counter, layers_used=range(4)):\n        super().__init__(webots_device, time_step, step_counter)\n        self.x = 0\n        self.y = 0\n        self.z = 0\n        self.orientation = Angle(0)\n        \n        self.horizontal_fov = self.device.getFov()\n        self.vertical_fov = self.device.getVerticalFov()\n\n        self.horizontal_resolution = self.device.getHorizontalResolution()\n        self.vertical_resolution = self.device.getNumberOfLayers()\n\n        self.radian_per_detection_horizontally = self.horizontal_fov / self.horizontal_resolution\n        self.radian_per_layer_vertically = self.vertical_fov / self.vertical_resolution\n\n        self.rotation_offset = 0\n\n        self.max_detection_distance = 0.06 * 8\n        self.min_detection_distance = 0.06 * 0.6\n\n        self.is_point_close = False\n        self.is_point_close_threshold = 0.03\n        self.is_point_close_range = (0, 360)\n\n        self.distance_bias = 0.005#0.06 * 0.12\n\n        self.layers_used = layers_used\n\n        self.__point_cloud = None\n        self.__out_of_bounds_point_cloud = None\n        self.__distance_detections = None\n\n    # Returns the in-bounds point cloud\n    def get_point_cloud(self):\n        if self.step_counter.check():\n            return self.__point_cloud\n    \n    # Returns a point cloud with all the out of bounds detections as points with a fixed distance\n    # to the center.\n    def get_out_of_bounds_point_cloud(self):\n        if self.step_counter.check():\n            return self.__out_of_bounds_point_cloud\n        \n    def get_detections(self):\n        if self.step_counter.check():\n            return self.__distance_detections\n\n    def set_orientation(self, angle):\n        self.orientation = angle\n\n\n    def update(self):\n        super().update()\n\n        # Do every n steps\n        if self.step_counter.check():\n            self.__update_point_clouds()\n\n\n    # Create point clouds from detections and check if a point is close\n    def __update_point_clouds(self):\n        self.is_point_close = False\n        \n        # (degsToRads(359 - radsToDegs(self.rotation)))\n        # rangeImage = self.device.getRangeImageArray()\n        # print("Lidar vFov: ", self.verticalFov/ self.verticalRes)\n\n        self.__point_cloud = []\n        self.__out_of_bounds_point_cloud = []\n        self.__distance_detections = []\n\n        total_depth_array = self.device.getRangeImage()\n        total_depth_array = divide_into_chunks(total_depth_array, self.horizontal_resolution)\n        #print(total_depth_array)\n        \n        for layer_number, layer_depth_array in enumerate(total_depth_array):\n            if layer_number not in self.layers_used:\n                continue\n\n            vertical_angle = layer_number * self.radian_per_layer_vertically + self.vertical_fov / 2\n            horizontal_angle = self.rotation_offset + ((2 * math.pi) - self.orientation.radians)\n\n            for item in layer_depth_array:\n                # Item is out of bounds\n                if item >= self.max_detection_distance or item == float("inf") or item == float("inf") *-1:\n                    \n                    # Corrects for vertical rotation and adds offset\n                    distance = self.__normalize_distance(self.max_detection_distance, vertical_angle)\n                    # Calculates 2d point from distance and horizontal angle\n                    point = utilities.getCoordsFromRads(horizontal_angle, distance)\n                    self.__out_of_bounds_point_cloud.append(self.__normalize_point(point))\n                \n                # Item is in bounds\n                else:\n                    if item >= self.min_detection_distance:\n                        # Corrects for vertical rotation and adds offset\n                        distance = self.__normalize_distance(item, vertical_angle)\n                        # Calculates 2d point from distance and horizontal angle\n                        point = utilities.getCoordsFromRads(horizontal_angle, distance)\n                        self.__point_cloud.append(self.__normalize_point(point))\n\n                        v = Vector2D(Angle(horizontal_angle), distance)\n                        v.direction = Angle(math.pi) - v.direction\n                        v.direction.normalize()\n                        self.__distance_detections.append(v)\n                        \n                        #Check if point is close\n                        if self.__in_range_for_close_point(horizontal_angle) and distance < self.is_point_close_threshold:\n                            self.is_point_close = True\n\n                horizontal_angle += self.radian_per_detection_horizontally\n        \n        if len(self.__out_of_bounds_point_cloud) == 0:\n            self.__out_of_bounds_point_cloud = [[0, 0]]\n        \n        if len(self.__point_cloud) == 0:\n            self.__point_cloud = [[0, 0]]\n    \n    def __in_range_for_close_point(self, horizontal_angle):\n        return utilities.degsToRads(self.is_point_close_range[0]) > horizontal_angle > utilities.degsToRads(self.is_point_close_range[1])\n    \n    def __normalize_distance(self, distance, vertical_angle):\n        # Correct for vertical inclination\n        distance = distance * math.cos(vertical_angle)\n        # Add offset\n        distance += self.distance_bias\n        return distance\n\n    def __normalize_point(self, point):\n            return [point[0], point[1] * -1]\n\n')
    __stickytape_write_module('utilities.py', b'import math\nimport cv2 as cv\nimport numpy as np\nimport os\nfrom functools import wraps\n\nscript_dir = os.path.dirname(__file__)\nimage_dir = os.path.join(script_dir, "images")\n\ndef save_image(image, filename):\n    cv.imwrite(os.path.join(image_dir, filename), image)\n\n\ndef normalizeRads(rad):\n    rad %= 2 * math.pi\n    if rad < 0:\n        rad += 2 + math.pi\n    return rad\n\n# Converts from degrees to radians\ndef degsToRads(deg):\n    return deg * math.pi / 180\n\n# Converts from radians to degrees\ndef radsToDegs(rad):\n    return rad * 180 / math.pi\n\n# Converts a number from a range of value to another\ndef mapVals(val, in_min, in_max, out_min, out_max):\n    return (val - in_min) * (out_max - out_min) / (in_max - in_min) + out_min\n\n# Gets x, y coordinates from a given angle in radians and distance\ndef getCoordsFromRads(rad, distance):\n    y = float(distance * math.cos(rad))\n    x = float(distance * math.sin(rad))\n    return (x, y)\n\n# Gets x, y coordinates from a given angle in degrees and distance\ndef getCoordsFromDegs(deg, distance):\n    rad = degsToRads(deg)\n    y = float(distance * math.cos(rad))\n    x = float(distance * math.sin(rad))\n    return (x, y)\n\n\ndef multiplyLists(list1, list2):\n    finalList = []\n    for item1, item2 in zip(list1, list2):\n        finalList.append(item1 * item2)\n    return finalList\n\ndef sumLists(list1, list2):\n    finalList = []\n    for item1, item2 in zip(list1, list2):\n        finalList.append(item1 + item2)\n    return finalList\n\ndef substractLists(list1, list2):\n    finalList = []\n    for item1, item2 in zip(list1, list2):\n        finalList.append(item1 - item2)\n    return finalList\n\ndef divideLists(list1, list2):\n    finalList = []\n    for item1, item2 in zip(list1, list2):\n        finalList.append(item1 / item2)\n    return finalList\n\n\ndef draw_grid(image, square_size, offset = [0,0], color=255):\n    for y, row in enumerate(image):\n        for x, pixel in enumerate(row):\n            if (y + offset[1]) % square_size == 0 or (x + offset[0]) % square_size == 0:\n                if len(image.shape) == 3:\n                    image[y][x][:] = color\n                else:\n                    image[y][x] = color\n\ndef draw_poses(image, poses, color=255, back_image=None, xx_yy_format=False):\n    if xx_yy_format:\n        if back_image is not None:\n            in_bounds_x = (poses[0] < min(image.shape[0], back_image.shape[0]) - 1) & (poses[0] > 0)\n            in_bounds_y = (poses[1] < min(image.shape[1], back_image.shape[1]) - 1) & (poses[1] > 0)\n        else:\n            in_bounds_x = (poses[0] < image.shape[0] - 1) & (poses[0] > 0)\n            in_bounds_y = (poses[1] < image.shape[1] - 1) & (poses[1] > 0)\n        \n        poses = (poses[0][in_bounds_x & in_bounds_y], poses[1][in_bounds_x & in_bounds_y])\n\n        if back_image is None:\n            image[poses[1], poses[0], :] = color\n        else:\n            image[poses[1], poses[0], :] = back_image[poses[1], poses[0], :]\n        \n    else:\n        in_bounds = (poses[:, 0] >= 0) & (poses[:, 0] < image.shape[1]) & (poses[:, 1] >= 0) & (poses[:, 1] < image.shape[0])\n        poses = poses[in_bounds]\n\n        if back_image is None:\n            image[poses[:, 1], poses[:, 0], :] = color\n        else:\n            image[poses[:, 1], poses[:, 0], :] = back_image[poses[:, 1], poses[:, 0], :]\n            \n\ndef draw_squares_where_not_zero(image, square_size, offsets, color=(255, 255, 255)):\n    ref_image = image.copy()\n    for y in range(image.shape[0] // square_size):\n        for x in range(image.shape[1] // square_size):\n            square_points = [\n                (y * square_size)        + (square_size - offsets[1]),\n                ((y + 1) * square_size)  + (square_size - offsets[1]), \n                (x * square_size)        + (square_size - offsets[0]),\n                ((x + 1) * square_size)  + (square_size - offsets[0])]\n            square = ref_image[square_points[0]:square_points[1], square_points[2]:square_points[3]]\n            non_zero_count = np.count_nonzero(square)\n            if non_zero_count > 0:\n                #print("Non zero count: ", non_zero_count)\n                #print("max: ", np.max(square))\n                cv.rectangle(image, (square_points[2], square_points[0]), (square_points[3], square_points[1]), color, 3)\n\ndef get_squares(image, square_size, offsets):\n    grid = []\n    for y in range(image.shape[0] // square_size):\n        row = []\n        for x in range(image.shape[1] // square_size):\n            square_points = [\n                (y * square_size)        + (square_size - offsets[1]),\n                ((y + 1) * square_size)  + (square_size - offsets[1]), \n                (x * square_size)        + (square_size - offsets[0]),\n                ((x + 1) * square_size)  + (square_size - offsets[0])]\n            row.append(square_points)\n        grid.append(row)\n    return grid\n\ndef resize_image_to_fixed_size(image, size):\n    if image.shape[0] > size[0]:\n        ratio = size[0] / image.shape[0]\n\n        width = round(image.shape[1] * ratio)\n        final_image = cv.resize(image.astype(np.uint8), dsize=(width, size[0]))\n    \n    elif image.shape[1] > size[1]:\n        ratio = size[1] / image.shape[1]\n\n        height = round(image.shape[0] * ratio)\n        final_image = cv.resize(image.astype(np.uint8), dsize=(size[1], height))\n    \n    elif image.shape[1] >= image.shape[0]:\n        ratio = size[1] / image.shape[1]\n\n        height = round(image.shape[0] * ratio)\n        final_image = cv.resize(image.astype(np.uint8), dsize=(size[1], height), interpolation=cv.INTER_NEAREST)\n    \n    elif image.shape[0] >= image.shape[1]:\n        ratio = size[0] / image.shape[0]\n\n        width = round(image.shape[1] * ratio)\n        final_image = cv.resize(image.astype(np.uint8), dsize=(width, size[0]), interpolation=cv.INTER_NEAREST)\n    \n    return final_image\n\n\ndef divide_into_chunks(lst, n):\n    """Yield successive n-sized chunks from lst."""\n    for i in range(0, len(lst), n):\n        yield lst[i:i + n]\n')
    __stickytape_write_module('robot/devices/gps.py', b'from data_structures.vectors import Position2D\n\nfrom robot.devices.sensor import Sensor\n\nclass Gps(Sensor):\n    """\n    Tracks global position and rotation.\n    """\n    def __init__(self, webots_device, time_step, coords_multiplier=1):\n        super().__init__(webots_device, time_step)\n        self.multiplier = coords_multiplier\n        self.__prev_position = Position2D()\n        self.position = self.get_position()\n\n    def update(self):\n        """\n        Updates gps, must run every timestep.\n        """\n        self.__prev_position = self.position\n        self.position = self.get_position()\n\n    def get_position(self):\n        """\n        Returns the global position.\n        """\n        vals = self.device.getValues()\n        return Position2D(vals[0] * self.multiplier, vals[2] * self.multiplier)\n\n    def get_orientation(self):\n        """\n        Returns the global orientation according to gps. This is calculated from the difference in angle from the current position\n        to the position of the previous time_step (The robot must be driving perfectly straight for it to work).\n        """\n        if self.__prev_position != self.position:\n            accuracy = abs(self.position.get_distance_to(self.__prev_position))\n            if accuracy > 0.001:\n                angle = self.__prev_position.get_angle_to(self.position)\n                angle.normalize()\n                return angle\n        return None')
    __stickytape_write_module('robot/devices/gyroscope.py', b'from data_structures.angle import Angle\nfrom robot.devices.sensor import Sensor\n\n\nclass Gyroscope(Sensor):\n    """\n    Tracks global rotation.\n    """\n    def __init__(self, webots_device, index, time_step):\n        super().__init__(webots_device, time_step)\n        self.index = index\n        self.orientation = Angle(0)\n        self.angular_velocity = Angle(0)\n\n    def update(self):\n        """\n        Do on every timestep.\n        """\n        time_elapsed = self.time_step / 1000\n        sensor_y_value = self.device.getValues()[self.index]\n        self.angular_velocity = Angle(sensor_y_value * time_elapsed)\n        self.orientation += self.angular_velocity\n        self.orientation.normalize()\n\n    def get_angular_velocity(self):\n        """\n        Gets the current angular velocity without direction data.\n        """\n        return abs(self.angular_velocity)\n\n    def get_orientation(self):\n        return self.orientation\n    \n    def set_orientation(self, angle):\n        self.orientation = angle')
    __stickytape_write_module('robot/devices/comunicator.py', b'import utilities\nimport struct\n\nfrom robot.devices.sensor import Sensor\n\nfrom flags import SHOW_MAP_AT_END\n\nclass Comunicator(Sensor):\n    def __init__(self, emmiter, receiver, timeStep):\n        self.receiver = receiver\n        self.emmiter = emmiter\n        self.receiver.enable(timeStep)\n        self.lack_of_progress = False\n        self.do_get_world_info = True\n        self.game_score = 0\n        self.remaining_time = 0\n\n    def send_victim(self, position, victimtype):\n        self.do_get_world_info = False\n        letter = bytes(victimtype, "utf-8")\n        position = utilities.multiplyLists(position, [100, 100])\n        position = [int(position[0]), int(position[1])]\n        message = struct.pack("i i c", position[0], position[1], letter)\n        self.emmiter.send(message)\n        self.do_get_world_info = False\n\n    def send_lack_of_progress(self):\n        self.do_get_world_info = False\n        message = struct.pack(\'c\', \'L\'.encode())  # message = \'L\' to activate lack of progress\n        self.emmiter.send(message)\n        self.do_get_world_info = False\n\n    def send_end_of_play(self):\n        self.do_get_world_info = False\n        exit_mes = struct.pack(\'c\', b\'E\')\n        self.emmiter.send(exit_mes)\n        print("Ended!!!!!")\n\n    def send_map(self, np_array):\n        # Get shape\n        if SHOW_MAP_AT_END:\n            print(np_array)\n        s = np_array.shape\n        # Get shape as bytes\n        s_bytes = struct.pack(\'2i\', *s)\n        # Flattening the matrix and join with \',\'\n        flatMap = \',\'.join(np_array.flatten())\n        # Encode\n        sub_bytes = flatMap.encode(\'utf-8\')\n        # Add togeather, shape + map\n        a_bytes = s_bytes + sub_bytes\n        # Send map data\n        self.emmiter.send(a_bytes)\n        # STEP3 Send map evaluate request\n        map_evaluate_request = struct.pack(\'c\', b\'M\')\n        self.emmiter.send(map_evaluate_request)\n        self.do_get_world_info = False\n\n    def request_game_data(self):\n        if self.do_get_world_info:\n            message = struct.pack(\'c\', \'G\'.encode())  # message = \'G\' for game information\n            self.emmiter.send(message)  # send message\n\n    def update(self):\n        if self.do_get_world_info:\n            self.request_game_data()\n            if self.receiver.getQueueLength() > 0: # If receiver queue is not empty\n                received_data = self.receiver.getBytes()\n                if len(received_data) > 2:\n                    tup = struct.unpack(\'c f i\', received_data) # Parse data into char, float, int\n                    if tup[0].decode("utf-8") == \'G\':\n                        self.game_score = tup[1]\n                        self.remaining_time = tup[2]\n                        self.receiver.nextPacket() # Discard the current data packet\n\n            self.lack_of_progress = False\n            if self.receiver.getQueueLength() > 0:  # If receiver queue is not empty\n                received_data = self.receiver.getBytes()\n                print(received_data)\n                if len(received_data) < 2:\n                    tup = struct.unpack(\'c\', received_data)  # Parse data into character\n                    if tup[0].decode("utf-8") == \'L\':  # \'L\' means lack of progress occurred\n                        print("Detected Lack of Progress!")\n                        self.lack_of_progress = True\n                    self.receiver.nextPacket()  # Discard the current data packetelse:\n        else:\n            self.do_get_world_info = True')
    __stickytape_write_module('robot/pose_manager.py', b'from robot.devices.gps import Gps\nfrom robot.devices.gyroscope import Gyroscope\nfrom data_structures.angle import Angle\nfrom data_structures.vectors import Position2D\n\nfrom flags import SHOW_DEBUG\n\n\nclass PoseManager:\n    GPS = 0\n    GYROSCOPE = 1\n\n    def __init__(self, gps: Gps, gyroscope: Gyroscope, position_offsets=Position2D(0, 0)) -> None:\n        self.maximum_angular_velocity_for_gps = 0.00001\n\n        self.gps = gps\n        self.gyroscope = gyroscope\n\n        self.orientation = Angle(0)\n        self.previous_orientation = Angle(0)\n\n        self.__position = Position2D(0, 0)\n        self.__previous_position = Position2D(0, 0)\n\n        self.orientation_sensor = self.GYROSCOPE\n        self.automatically_decide_orientation_sensor = True\n\n        self.position_offsets = position_offsets\n    \n    def update(self, wheel_direction):\n        # Gyro and gps update\n        self.gps.update()\n        self.gyroscope.update()\n        \n        # Get global position\n        self.__previous_position = self.position\n        self.__position = self.gps.get_position()\n\n        # Decides wich sensor to use for orientation detection\n        if self.automatically_decide_orientation_sensor:\n            self.decide_orientation_sensor(wheel_direction)\n\n        # Remembers the corrent rotation for the next timestep\n        self.previous_orientation = self.orientation\n\n        self.calculate_orientation()\n\n    def decide_orientation_sensor(self, wheel_direction):\n        """if the robot is going srtaight it tuses the gps. If not it uses the gyro."""\n        if self.robot_is_going_straight(wheel_direction):\n                self.orientation_sensor = self.GPS\n        else:\n            self.orientation_sensor = self.GYROSCOPE\n\n    def robot_is_going_straight(self, wheel_direction):\n        return self.gyroscope.get_angular_velocity() < self.maximum_angular_velocity_for_gps and wheel_direction >= 0\n\n    def calculate_orientation(self):\n        \n         # Gets global rotation\n        gps_orientation = self.gps.get_orientation()\n\n        if self.orientation_sensor == self.GYROSCOPE or gps_orientation is None:\n            self.orientation = self.gyroscope.get_orientation()\n            if SHOW_DEBUG: print("USING GYRO")\n        else:\n            self.orientation = gps_orientation\n            self.gyroscope.set_orientation(self.orientation)\n            if SHOW_DEBUG: print("USING GPS")\n\n    @property\n    def position(self):\n        return self.__position + self.position_offsets\n    \n    @property\n    def raw_position(self):\n        return self.__position\n    \n    @property\n    def previous_position(self):\n        return self.__previous_position + self.position_offsets\n        \n\n')
    __stickytape_write_module('robot/drive_base.py', b'from utilities import mapVals\nfrom enum import Enum\nfrom data_structures.angle import Angle\nfrom data_structures.vectors import Position2D, Vector2D\nimport math\nfrom flags import SHOW_DEBUG\n\nfrom robot.devices.wheel import Wheel\n\nclass Criteria(Enum):\n    LEFT = 1\n    RIGHT = 2\n    CLOSEST = 3\n    FARTHEST = 4\n\nclass DriveBase:\n    def __init__(self, left_wheel, right_wheel, max_wheel_velocity) -> None:\n        self.max_wheel_velocity = max_wheel_velocity\n        self.left_wheel = left_wheel\n        self.right_wheel = right_wheel\n        self.rotation_manager = RotationManager(self.left_wheel, self.right_wheel)\n        self.slow_rotation_manager = RotationManager(self.left_wheel, self.right_wheel)\n        self.slow_rotation_manager.max_velocity = 0.4\n        self.slow_rotation_manager.max_velocity_cap = 0.4\n        #self.movement_manager = MovementToCoordinatesManager(self.left_wheel, self.right_wheel)\n        self.movement_manager = SmoothMovementToCoordinatesManager(self.left_wheel, self.right_wheel)\n\n    # Moves the wheels at the specified Velocity\n    def move_wheels(self, left_ratio, right_ratio):\n        self.left_wheel.move(left_ratio)\n        self.right_wheel.move(right_ratio)\n    \n    def rotate_to_angle(self, angle:Angle, criteria:Criteria.CLOSEST) -> bool:\n        self.rotation_manager.rotate_to_angle(angle, criteria)\n        return self.rotation_manager.finished_rotating\n    \n    def rotate_slowly_to_angle(self, angle:Angle, criteria:Criteria.CLOSEST) -> bool:\n        self.slow_rotation_manager.rotate_to_angle(angle, criteria)\n        return self.slow_rotation_manager.finished_rotating\n    \n    def move_to_position(self, position:Position2D) -> bool:\n        self.movement_manager.move_to_position(position)\n        return self.movement_manager.finished_moving\n    \n    @property\n    def position(self) -> Position2D:\n        return self.movement_manager.current_position\n    \n    @position.setter\n    def position(self, value:Position2D):\n        self.movement_manager.current_position = value\n\n    @property\n    def orientation(self) -> Angle:\n        return self.rotation_manager.current_angle\n    \n    @orientation.setter\n    def orientation(self, value:Angle):\n        self.movement_manager.current_angle = value\n        self.rotation_manager.current_angle = value\n        self.slow_rotation_manager.current_angle = value\n\n\n    def get_wheel_direction(self):\n        if self.right_wheel.velocity + self.left_wheel.velocity == 0:\n            return 0\n        return (self.right_wheel.velocity + self.left_wheel.velocity) / 2\n\n\nclass RotationManager:\n    def __init__(self, left_wheel, right_wheel) -> None:\n        self.Directions = Enum("Directions", ["LEFT", "RIGHT"])\n        \n        self.right_wheel = right_wheel\n        self.left_wheel = left_wheel\n\n        self.initial_angle = Angle(0)\n        self.current_angle = Angle(0)\n\n        self.first_time = True\n        self.finished_rotating = True\n\n        self.max_velocity_cap = 1\n        self.min_velocity_cap = 0.2\n\n        self.max_velocity = 1\n        self.min_velocity = 0.2\n\n        self.velocity_reduction_threshold = Angle(10, Angle.DEGREES)\n        self.velocity_reduction_factor = 0.5\n\n        self.accuracy = Angle(2, Angle.DEGREES)\n\n    def rotate_to_angle(self, target_angle, criteria=Criteria.CLOSEST):\n        if self.first_time:\n            self.initial_angle = self.current_angle\n            self.first_time = False\n            self.finished_rotating = False\n\n        if self.is_at_angle(target_angle):\n            self.finished_rotating = True\n            self.first_time = True\n            self.left_wheel.move(0)\n            self.right_wheel.move(0)\n\n        absolute_difference = self.current_angle.get_absolute_distance_to(target_angle)\n        velocity = mapVals(absolute_difference.degrees, self.accuracy.degrees, 90, self.min_velocity, self.max_velocity)\n\n        if absolute_difference < self.velocity_reduction_threshold:\n            velocity *= self.velocity_reduction_factor\n\n        velocity = min(velocity, self.max_velocity_cap)\n        velocity = max(velocity, self.min_velocity_cap)\n\n\n        direction = self.__get_direction(target_angle, criteria)\n        \n        if direction == self.Directions.RIGHT:\n            self.left_wheel.move(velocity * -1)\n            self.right_wheel.move(velocity)\n        elif direction == self.Directions.LEFT:\n            self.left_wheel.move(velocity)\n            self.right_wheel.move(velocity * -1)\n    \n    def is_at_angle(self, angle) -> bool:\n        return self.current_angle.get_absolute_distance_to(angle) < self.accuracy\n\n    def __get_direction(self, target_angle, criteria):\n        if criteria == Criteria.CLOSEST:\n            angle_difference = self.current_angle - target_angle\n\n            if 180 > angle_difference.degrees > 0 or angle_difference.degrees < -180:\n                return self.Directions.RIGHT\n            else:\n                return self.Directions.LEFT\n\n        elif criteria == Criteria.FARTHEST:\n            angle_difference = self.initial_angle - target_angle\n            if 180 > angle_difference.degrees > 0 or angle_difference.degrees < -180:\n                return self.Directions.LEFT\n            else:\n                return self.Directions.RIGHT\n\n        elif criteria == Criteria.LEFT: return self.Directions.LEFT\n        elif criteria == Criteria.RIGHT: return self.Directions.RIGHT\n\n\nclass MovementToCoordinatesManager:\n    def __init__(self, left_wheel, right_wheel) -> None:\n        self.current_position = Position2D()\n\n        self.left_wheel = left_wheel\n        self.right_wheel = right_wheel\n        self.rotation_manager = RotationManager(self.left_wheel, self.right_wheel)\n\n        #self.error_margin = 0.0005\n        self.error_margin = 0.001\n        self.desceleration_start = 0.5 * 0.12\n\n        self.max_velocity_cap = 1\n        self.min_velocity_cap = 0.8\n\n        self.max_velocity = 1\n        self.min_velocity = 0.1\n\n        self.finished_moving = False\n\n    @property\n    def current_angle(self) -> Angle:\n        return self.rotation_manager.current_angle\n    \n    @current_angle.setter\n    def current_angle(self, value):\n        self.rotation_manager.current_angle = value\n\n    \n    def move_to_position(self, target_position:Position2D):\n\n        # print("Target Pos: ", targetPos)\n        # print("Used global Pos: ", self.position)\n\n        dist = abs(self.current_position.get_distance_to(target_position))\n\n        if SHOW_DEBUG: print("Dist: "+ str(dist))\n\n        if dist < self.error_margin:\n            # self.robot.move(0,0)\n            if SHOW_DEBUG: print("FinisehedMove")\n            self.finished_moving = True\n        else:\n            self.finished_moving = False\n            ang = self.current_position.get_angle_to(target_position)\n\n            if self.rotation_manager.is_at_angle(ang):\n\n                velocity = mapVals(dist, 0, self.desceleration_start, self.min_velocity, self.max_velocity)\n                velocity = min(velocity, self.max_velocity_cap)\n                velocity = max(velocity, self.min_velocity_cap)\n\n                self.right_wheel.move(velocity)\n                self.left_wheel.move(velocity)\n\n\n            else:\n                \n                self.rotation_manager.rotate_to_angle(ang)\n\n\nclass SmoothMovementToCoordinatesManager:\n    def __init__(self, left_wheel: Wheel, right_wheel: Wheel) -> None:\n        self.current_position = Position2D()\n\n        self.left_wheel = left_wheel\n        self.right_wheel = right_wheel\n\n        self.current_angle = Angle(0)\n\n        self.error_margin = 0.003\n\n        self.velocity = 1\n\n        self.distance_weight = 5\n        self.angle_weight = 5\n\n        self.min_velocity_cap = 0\n\n        self.turning_speed_multiplier = 0.5\n\n        self.finished_moving = False\n\n        self.angle_error_margin = Angle(3, Angle.DEGREES)\n\n        self.strong_rotation_start = Angle(45, Angle.DEGREES)\n\n        self.light_rotation_start = Angle(30, Angle.DEGREES)\n\n    def move_to_position(self, target_position:Position2D):\n        dist = abs(self.current_position.get_distance_to(target_position))\n\n        if SHOW_DEBUG: print("Dist: "+ str(dist))\n\n        if dist < self.error_margin:\n            # self.robot.move(0,0)\n            if SHOW_DEBUG: print("FinisehedMove")\n            self.finished_moving = True\n\n\n        else:\n            self.finished_moving = False\n\n            angle_to_target = self.current_position.get_angle_to(target_position)\n            angle_diff = self.current_angle - angle_to_target\n            absolute_angle_diff = self.current_angle.get_absolute_distance_to(angle_to_target)\n\n            if absolute_angle_diff < self.angle_error_margin:\n                #print("straight")\n                self.right_wheel.move(self.velocity)\n                self.left_wheel.move(self.velocity)\n\n\n            elif absolute_angle_diff > self.strong_rotation_start:\n                #print("strong")\n                if 180 > angle_diff.degrees > 0 or angle_diff.degrees < -180:\n                    self.right_wheel.move(self.velocity)\n                    self.left_wheel.move(self.velocity * -1)\n                else:\n                    self.right_wheel.move(self.velocity * -1)\n                    self.left_wheel.move(self.velocity)\n            \n            elif absolute_angle_diff < self.light_rotation_start:\n                #print("light")\n                if 180 > angle_diff.degrees > 0 or angle_diff.degrees < -180:\n                    self.right_wheel.move(1)\n                    self.left_wheel.move(0.8)\n                else:\n                    self.right_wheel.move(0.8)\n                    self.left_wheel.move(1)\n\n\n            else:\n                #print("dynamic")\n                distance_speed = abs(dist * -self.distance_weight)\n                angle_speed = absolute_angle_diff.radians * self.angle_weight\n\n                speed = angle_speed * self.turning_speed_multiplier\n\n                speed = max(self.min_velocity_cap, speed)\n\n                speed2 = speed * distance_speed\n                speed2 = max(speed2, self.min_velocity_cap)\n\n                if 180 > angle_diff.degrees > 0 or angle_diff.degrees < -180:\n                    self.right_wheel.move(speed)\n                    self.left_wheel.move(speed2)\n                else:\n                    self.right_wheel.move(speed2)\n                    self.left_wheel.move(speed)\n\n\n            #print("Wheel vel:", self.right_wheel.velocity / 6.28 , self.left_wheel.velocity / 6.28)\n                \n                \n    \n\n')
    __stickytape_write_module('mapping/mapper.py', b'from copy import copy, deepcopy\n\nimport numpy as np\nimport cv2 as cv\n\nfrom data_structures.vectors import Position2D\nfrom data_structures.angle import Angle\n\nfrom data_structures.compound_pixel_grid import CompoundExpandablePixelGrid\nfrom data_structures.tile_color_grid import TileColorExpandableGrid\n\nfrom mapping.wall_mapper import WallMapper\nfrom mapping.floor_mapper import FloorMapper\n\nfrom mapping.array_filtering import ArrayFilterer\n\nfrom mapping.robot_mapper import RobotMapper\nfrom mapping.fixture_mapper import FixtureMapper\n\nfrom mapping.data_extractor import PointCloudExtarctor, FloorColorExtractor\nfrom fixture_detection.fixture_detection import FixtureDetector\n\nfrom flags import SHOW_DEBUG, SHOW_GRANULAR_NAVIGATION_GRID, DO_WAIT_KEY\n\n\nclass Mapper:\n    def __init__(self, tile_size, robot_diameter, camera_distance_from_center):\n        self.tile_size = tile_size\n        self.quarter_tile_size = tile_size / 2\n        self.robot_diameter = robot_diameter\n\n        self.robot_position = None\n        self.robot_orientation = None\n        self.start_position = None\n\n        self.robot_grid_index = None\n\n        # Data structures\n        pixels_per_tile = 10\n        self.pixel_grid = CompoundExpandablePixelGrid(initial_shape=np.array([1, 1]), \n                                                      pixel_per_m=pixels_per_tile / self.quarter_tile_size, \n                                                      robot_radius_m=(self.robot_diameter / 2) -0.008)\n        \n        self.tile_color_grid = TileColorExpandableGrid(initial_shape=np.array((1, 1)),\n                                                       tile_size=self.tile_size)\n\n        #Data processors\n        self.wall_mapper = WallMapper(self.pixel_grid, robot_diameter)\n        self.floor_mapper = FloorMapper(pixel_grid=self.pixel_grid, \n                                        tile_resolution=pixels_per_tile * 2,\n                                        tile_size=self.tile_size,\n                                        camera_distance_from_center=camera_distance_from_center)\n        \n        self.filterer = ArrayFilterer()\n        \n        self.robot_mapper = RobotMapper(pixel_grid=self.pixel_grid,\n                                        robot_diameter=self.robot_diameter,\n                                        pixels_per_m=pixels_per_tile / self.quarter_tile_size)\n\n        self.fixture_mapper = FixtureMapper(pixel_grid=self.pixel_grid,\n                                            tile_size=self.tile_size)\n        \n\n        # Data extractors\n        self.point_cloud_extractor = PointCloudExtarctor(resolution=6)\n        self.floor_color_extractor = FloorColorExtractor(tile_resolution=50)\n\n        self.fixture_detector = FixtureDetector(self.pixel_grid)\n\n\n        self.time = 0\n\n    def update(self, in_bounds_point_cloud: list = None, \n               out_of_bounds_point_cloud: list = None,\n               lidar_detections: list = None,\n               camera_images: list = None, \n               robot_position: Position2D = None, \n               robot_orientation: Angle = None,\n               time = None):\n        \n        if time is not None:\n            self.time = time\n        \n        if robot_position is None or robot_orientation is None:\n            return\n        \n        self.robot_position = robot_position\n        self.robot_orientation = robot_orientation\n\n        self.robot_grid_index = self.pixel_grid.coordinates_to_grid_index(self.robot_position)\n\n        # Load walls and obstacles (Lidar detections)\n        if in_bounds_point_cloud is not None and out_of_bounds_point_cloud is not None:\n            self.wall_mapper.load_point_cloud(in_bounds_point_cloud, out_of_bounds_point_cloud, robot_position)\n        \n        self.robot_mapper.map_traversed_by_robot(self.robot_grid_index)\n        self.robot_mapper.map_seen_by_camera(self.robot_grid_index, self.robot_orientation)\n        self.robot_mapper.map_discovered_by_robot(self.robot_grid_index, self.robot_orientation)\n\n        self.fixture_mapper.generate_detection_zone()\n        self.fixture_mapper.clean_up_fixtures()\n\n        # Load floor colors\n        if camera_images is not None:\n            self.floor_mapper.map_floor(camera_images, self.pixel_grid.coordinates_to_grid_index(self.robot_position))\n\n        if camera_images is not None and lidar_detections is not None:\n            self.fixture_detector.map_fixtures(camera_images, self.robot_position)\n        \n        self.filterer.remove_isolated_points(self.pixel_grid.arrays["occupied"])\n\n        self.filterer.smooth_edges(self.pixel_grid.arrays["occupied"])\n\n        #DEBUG\n        if DO_WAIT_KEY:\n            cv.waitKey(1)\n\n    \n    def register_start(self, robot_position):\n        self.start_position = deepcopy(robot_position)\n        print("registered start position:", self.start_position)\n\n    \n    # Grids\n    def get_grid_for_bonus(self):\n        """\n        final_grid = []\n        for row in self.get_node_grid().grid:\n            final_row = []\n            for node in row:\n                final_row.append(node.get_representation())\n            final_grid.append(final_row)\n        return np.array(final_grid)\n        """\n        pass # TODO\n    \n\n    def __lidar_to_node_grid(self):\n        """\n        grid, offsets = self.point_cloud_extractor.transform_to_grid(self.lidar_grid)\n        for y, row in enumerate(grid):\n            for x, value in enumerate(row):\n                xx = (x - offsets[0]) * 2 + 1\n                yy = (y - offsets[1]) * 2 + 1\n                #print(value)\n                for direction in value:\n                    self.node_grid.load_straight_wall((xx, yy),  direction)\n        """\n\n    def has_detected_victim_from_position(self):\n        robot_array_index = self.pixel_grid.grid_index_to_array_index(self.robot_grid_index)\n        return self.pixel_grid.arrays["robot_detected_fixture_from"][robot_array_index[0], robot_array_index[1]]')
    __stickytape_write_module('data_structures/compound_pixel_grid.py', b'import numpy as np\nimport cv2 as cv\nimport copy\nfrom data_structures.vectors import Position2D, Vector2D\nfrom data_structures.angle import Angle\nimport math\nfrom flow_control.step_counter import StepCounter\n\n\nclass CompoundExpandablePixelGrid:\n    def __init__(self, initial_shape, pixel_per_m, robot_radius_m):\n        self.array_shape = np.array(initial_shape, dtype=int)\n        self.offsets = self.array_shape // 2\n        self.resolution = pixel_per_m # resolution of the grid with regards to the coordinate system of the gps / the world\n\n        self.arrays = {\n            "detected_points": np.zeros(self.array_shape, np.uint8), # Number of points detected in position\n            "walls": np.zeros(self.array_shape, np.bool_),\n            "occupied": np.zeros(self.array_shape, np.bool_), # Confirmed occupied point\n            "traversable": np.zeros(self.array_shape, np.bool_), # Is or not traversable by the robot, assuming that the robot center is there. True means not traversable.\n            "navigation_preference": np.zeros(self.array_shape, np.float32), # The preference for navigation for each pixel. More means less preferred to navigate through.\n            "traversed": np.zeros(self.array_shape, np.bool_), # Robot has already gone through there\n            "seen_by_camera": np.zeros(self.array_shape, np.bool_), # Has been seen by any of the cameras\n            "seen_by_lidar": np.zeros(self.array_shape, np.bool_), # Has been seen by the lidar (Though not necessarily detected as occupied)\n            "walls_seen_by_camera": np.zeros(self.array_shape, np.bool_),\n            "walls_not_seen_by_camera": np.zeros(self.array_shape, np.bool_),\n            "discovered": np.zeros(self.array_shape, np.bool_),\n            "floor_color": np.zeros((self.array_shape[0], self.array_shape[1], 3), np.uint8),\n            "floor_color_detection_distance": np.zeros(self.array_shape, np.uint8),\n            "average_floor_color": np.zeros((self.array_shape[0], self.array_shape[1], 3), np.uint8),\n            "holes": np.zeros(self.array_shape, np.bool_),\n            "victims": np.zeros(self.array_shape, np.bool_),\n            "victim_angles": np.zeros(self.array_shape, np.float32),\n            "fixture_detection": np.zeros(self.array_shape, np.bool_),\n            "fixture_detection_zone": np.zeros(self.array_shape, np.bool_),\n            "fixture_distance_margin": np.zeros(self.array_shape, np.bool_),\n            "robot_detected_fixture_from": np.zeros(self.array_shape, np.bool_),\n            "robot_center_traversed": np.zeros(self.array_shape, np.bool_),\n        }\n\n    @property\n    def grid_index_max(self):\n        return self.array_shape - self.offsets # Maximum grid index\n    \n    @property\n    def grid_index_min(self):\n        return self.offsets * -1 # Minimum grid index\n\n    # Index conversion\n    def coordinates_to_grid_index(self, coordinates: np.ndarray) -> np.ndarray:\n        coords = (coordinates * self.resolution).astype(int)\n        return np.flip(coords)\n\n    def grid_index_to_coordinates(self, grid_index: np.ndarray) -> np.ndarray:\n        index = (grid_index.astype(float) / self.resolution)\n        return np.flip(index)\n\n    def array_index_to_grid_index(self, array_index: np.ndarray) -> np.ndarray:\n        return array_index - self.offsets\n    \n    def grid_index_to_array_index(self, grid_index: np.ndarray) -> np.ndarray:\n        return grid_index + self.offsets\n    \n    def array_index_to_coordinates(self, array_index) -> np.ndarray:\n        grid_index = self.array_index_to_grid_index(array_index)\n        return self.grid_index_to_coordinates(grid_index)\n    \n    def coordinates_to_array_index(self, coordinates) -> np.ndarray:\n        grid_index = self.coordinates_to_grid_index(coordinates)\n        return self.grid_index_to_array_index(grid_index)\n\n    # Grid expansion\n    def expand_to_grid_index(self, grid_index: np.ndarray):\n        """\n        Expands all arrays to the specified index. \n        Note that all array_idexes should be recalculated after this operation.\n        """\n\n        array_index = self.grid_index_to_array_index(grid_index)\n        if array_index[0] + 1 > self.array_shape[0]:\n            self.add_end_row(array_index[0] - self.array_shape[0] + 1)\n\n        if array_index[1] + 1 > self.array_shape[1]:\n            self.add_end_column(array_index[1] - self.array_shape[1] + 1)\n\n        if array_index[0] < 0:\n            self.add_begining_row(array_index[0] * -1)\n        if array_index[1] < 0:\n            self.add_begining_column(array_index[1] * -1)\n    \n    def add_end_row(self, size):\n        self.array_shape = np.array([self.array_shape[0] + size, self.array_shape[1]])\n        \n        for key in self.arrays:\n            self.arrays[key] = self.__add_end_row_to_grid(self.arrays[key], size)\n        \n    def add_begining_row(self, size):\n        self.offsets[0] += size\n        self.array_shape = np.array([self.array_shape[0] + size, self.array_shape[1]])\n\n        for key in self.arrays:\n            self.arrays[key] = self.__add_begining_row_to_grid(self.arrays[key], size)\n\n    def add_end_column(self, size):\n        self.array_shape = np.array([self.array_shape[0], self.array_shape[1] + size])\n\n        for key in self.arrays:\n            self.arrays[key] = self.__add_end_column_to_grid(self.arrays[key], size)\n\n    def add_begining_column(self, size):\n        self.offsets[1] += size\n        self.array_shape = np.array([self.array_shape[0], self.array_shape[1] + size])\n\n        for key in self.arrays:\n            self.arrays[key] = self.__add_begining_column_to_grid(self.arrays[key], size)\n\n    def __add_end_row_to_grid(self, grid, size):\n        shape = np.array(grid.shape)\n        shape[0] = size\n        shape[1] = self.array_shape[1]\n        grid = np.vstack((grid, np.zeros(shape, dtype=grid.dtype)))\n        return grid\n    \n    def __add_begining_row_to_grid(self, grid, size):\n        shape = np.array(grid.shape)\n        shape[0] = size\n        shape[1] = self.array_shape[1]\n        grid = np.vstack((np.zeros(shape, dtype=grid.dtype), grid))\n        return grid\n    \n    def __add_end_column_to_grid(self, grid, size):\n        shape = np.array(grid.shape)\n        shape[0] = self.array_shape[0]\n        shape[1] = size\n        grid = np.hstack((grid, np.zeros(shape, dtype=grid.dtype)))\n        return grid\n\n    def __add_begining_column_to_grid(self, grid, size):\n        shape = np.array(grid.shape)\n        shape[0] = self.array_shape[0]\n        shape[1] = size\n        grid = np.hstack((np.zeros(shape, dtype=grid.dtype), grid))\n        return grid\n\n    # Debug\n    def get_colored_grid(self):\n        """\n        Get graphical representation of the grid for debug.\n        """\n        #color_grid = np.zeros((self.array_shape[0], self.array_shape[1], 3), dtype=np.float32)\n        color_grid = self.arrays["floor_color"].astype(np.float32) / 255\n        \n        #color_grid[:, :, 1] = self.arrays["navigation_preference"][:, :] / 200\n        color_grid[self.arrays["traversable"]] = (1, 0, 0)\n        \n        #color_grid[self.arrays["discovered"]] = (0, 1, 1)\n        #color_grid[self.arrays["seen_by_camera"]] += (0.5, 0, 0)\n        #color_grid[self.arrays["fixture_detection_zone"]] = (0, 1, 1)\n        color_grid[self.arrays["fixture_distance_margin"]] = (0, 0, 1)\n\n\n        color_grid[self.arrays["occupied"]] = (1, 1, 1)\n\n        #color_grid[self.arrays["walls_not_seen_by_camera"]] = (0, 0, 1)\n\n        color_grid *= 0.3\n\n        color_grid[self.arrays["victims"]] = (0, 1, 0)\n\n        color_grid[self.arrays["robot_center_traversed"]] = (.5, 0., .5)\n        \n \n        return color_grid')
    __stickytape_write_module('data_structures/tile_color_grid.py', b'import numpy as np\nimport cv2 as cv\nimport copy\n\n\nclass TileColorExpandableGrid:\n    def __init__(self, initial_shape, tile_size):\n        self.array_shape = np.array(initial_shape, dtype=int)\n        self.offsets = self.array_shape // 2\n\n        self.grid_index_max = self.array_shape - self.offsets # Maximum grid index\n        self.grid_index_min = self.offsets * -1 # Minimum grid index\n\n        self.array = np.zeros(self.array_shape, np.bool_)\n\n        self.resolution = 1 / tile_size # resolution of the grid with regards to the coordinate system of the gps / the world\n    \n    # Index conversion\n    def coordinates_to_grid_index(self, coordinates: np.ndarray) -> np.ndarray:\n        coords = (coordinates * self.resolution).astype(int)\n        return np.flip(coords)\n\n    def grid_index_to_coordinates(self, grid_index: np.ndarray) -> np.ndarray:\n        index = (grid_index.astype(float) / self.resolution)\n        return np.flip(index)\n\n    def array_index_to_grid_index(self, array_index: np.ndarray) -> np.ndarray:\n        return array_index - self.offsets\n    \n    def grid_index_to_array_index(self, grid_index: np.ndarray) -> np.ndarray:\n        return grid_index + self.offsets\n    \n    def array_index_to_coordinates(self, array_index) -> np.ndarray:\n        grid_index = self.array_index_to_grid_index(array_index)\n        return self.grid_index_to_coordinates(grid_index)\n    \n    def coordinates_to_array_index(self, coordinates) -> np.ndarray:\n        grid_index = self.coordinates_to_grid_index(coordinates)\n        return self.grid_index_to_array_index(grid_index)\n\n    # Grid expansion\n    def expand_to_grid_index(self, grid_index: np.ndarray):\n        """\n        Expands all arrays to the specified index. \n        Note that all array_idexes should be recalculated after this operation.\n        """\n\n        array_index = self.grid_index_to_array_index(grid_index)\n        if array_index[0] + 1 > self.array_shape[0]:\n            self.add_end_row(array_index[0] - self.array_shape[0] + 1)\n\n        if array_index[1] + 1 > self.array_shape[1]:\n            self.add_end_column(array_index[1] - self.array_shape[1] + 1)\n\n        if array_index[0] < 0:\n            self.add_begining_row(array_index[0] * -1)\n        if array_index[1] < 0:\n            self.add_begining_column(array_index[1] * -1)\n    \n    def add_end_row(self, size):\n        self.array_shape = np.array([self.array_shape[0] + size, self.array_shape[1]])\n        \n        self.array = self.__add_end_row_to_array(self.array, size)\n        \n    def add_begining_row(self, size):\n        self.offsets[0] += size\n        self.array_shape = np.array([self.array_shape[0] + size, self.array_shape[1]])\n\n        self.array = self.__add_begining_row_to_array(self.array, size)\n\n    def add_end_column(self, size):\n        self.array_shape = np.array([self.array_shape[0], self.array_shape[1] + size])\n\n        self.array = self.__add_end_column_to_array(self.array, size)\n\n    def add_begining_column(self, size):\n        self.offsets[1] += size\n        self.array_shape = np.array([self.array_shape[0], self.array_shape[1] + size])\n\n        self.array = self.__add_begining_column_to_array(self.array, size)\n\n    def __add_end_row_to_array(self, array, size):\n        array = np.vstack((array, np.zeros((size, self.array_shape[1]), dtype=array.dtype)))\n        return array\n    \n    def __add_begining_row_to_array(self, array, size):\n        array = np.vstack((np.zeros((size, self.array_shape[1]), dtype=array.dtype), array))\n        return array\n    \n    def __add_end_column_to_array(self, array, size):\n        array = np.hstack((array, np.zeros((self.array_shape[0], size), dtype=array.dtype)))\n        return array\n\n    def __add_begining_column_to_array(self, array, size):\n        array = np.hstack((np.zeros((self.array_shape[0], size), dtype=array.dtype), array))\n        return array\n    \n    # Debug\n    def get_colored_grid(self):\n       pass\n    ')
    __stickytape_write_module('mapping/wall_mapper.py', b'import numpy as np\nimport cv2 as cv\nfrom data_structures.compound_pixel_grid import CompoundExpandablePixelGrid\n\nfrom data_structures.vectors import Position2D\n\nimport skimage\n\nclass WallMapper:\n    def __init__(self, compound_grid: CompoundExpandablePixelGrid, robot_diameter: float) -> None:\n        self.grid = compound_grid\n\n        compensation = 0\n\n        self.robot_diameter = int(robot_diameter * self.grid.resolution) + compensation * 2\n        self.robot_radius = int(robot_diameter / 2 * self.grid.resolution) + compensation\n\n        self.to_boolean_threshold = 3\n        self.delete_threshold = 1\n        \n        # Circle with the radius of the robot\n        self.robot_diameter_template = np.zeros((self.robot_diameter, self.robot_diameter), dtype=np.uint8)\n        self.robot_diameter_template = cv.circle(self.robot_diameter_template, (self.robot_radius, self.robot_radius), self.robot_radius, 255, -1)\n        self.robot_diameter_template = self.robot_diameter_template.astype(np.bool_)\n\n        # A template to calculated the preference of each pixel for navigation taking into account the distance from the wall\n        #self.preference_template = self.__generate_quadratic_circle_gradient(self.robot_radius, self.robot_radius * 2)\n        self.preference_template = self.__generate_quadratic_circle_gradient(self.robot_radius, self.robot_radius * 1.7)\n\n\n\n\n    def load_point_cloud(self, in_bounds_point_cloud, out_of_bounds_point_cloud, robot_position):\n        """\n        Loads into the corresponding arrays what has been seen by the lidar, what the lidar has detected, and\n        what walls the lidar has detected but the camera hasn\'t seen.\n        Calculates the travesable areas and the preference of each point for navigation.\n        """\n        \n        \n        robot_position_as_array = np.array(robot_position, dtype=float)\n        \n        self.__reset_seen_by_lidar()\n\n        self.load_in_bounds_point_cloud(in_bounds_point_cloud, robot_position_as_array)\n        self.load_out_of_bounds_point_cloud(out_of_bounds_point_cloud, robot_position_as_array)\n\n\n    def load_in_bounds_point_cloud(self, point_cloud, robot_position):\n        for p in point_cloud:\n            point = np.array(p, dtype=float) + robot_position\n\n            point_grid_index = self.grid.coordinates_to_grid_index(point)\n\n            self.grid.expand_to_grid_index(point_grid_index)\n\n            robot_array_index = self.grid.coordinates_to_array_index(robot_position)\n            point_array_index = self.grid.grid_index_to_array_index(point_grid_index)\n\n            self.occupy_point(point_array_index)\n\n            self.mark_point_as_seen_by_lidar(robot_array_index, point_array_index)\n            \n        self.filter_out_noise()\n\n        self.generate_navigation_margins()\n\n    def load_out_of_bounds_point_cloud(self, point_cloud, robot_position):\n        for p in point_cloud:\n            point = np.array(p, dtype=float) + robot_position\n\n            point_grid_index = self.grid.coordinates_to_grid_index(point)\n            self.grid.expand_to_grid_index(point_grid_index)\n\n            robot_array_index = self.grid.coordinates_to_array_index(robot_position)\n            point_array_index = self.grid.grid_index_to_array_index(point_grid_index)\n\n            self.mark_point_as_seen_by_lidar(robot_array_index, point_array_index)\n\n        self.calculate_seen_walls()\n\n    def calculate_seen_walls(self):\n        self.grid.arrays["walls_seen_by_camera"] = self.grid.arrays["seen_by_camera"] * self.grid.arrays["walls"]\n        self.grid.arrays["walls_not_seen_by_camera"] =  np.logical_xor(self.grid.arrays["walls"], self.grid.arrays["walls_seen_by_camera"])\n\n    def generate_navigation_margins(self):\n        # Areas traversable by the robot\n        occupied_as_int = self.grid.arrays["occupied"].astype(np.uint8)\n        diameter_template_as_int = self.robot_diameter_template.astype(np.uint8)\n\n        self.grid.arrays["traversable"] = cv.filter2D(occupied_as_int, -1, diameter_template_as_int)\n        self.grid.arrays["traversable"] = self.grid.arrays["traversable"].astype(np.bool_)\n\n        # Areas that the robot prefers to navigate through\n        self.grid.arrays["navigation_preference"] = cv.filter2D(occupied_as_int, -1, self.preference_template)\n\n    def filter_out_noise(self):\n        """\n        Filters out noise from the \'detected_points\' array.\n        """\n        self.grid.arrays["detected_points"] = self.grid.arrays["detected_points"] * (self.grid.arrays["detected_points"] > self.delete_threshold)\n\n\n    # Initialization methods\n    def __generate_quadratic_circle_gradient(self, min_radius, max_radius):\n        min_radius = round(min_radius)\n        max_radius = round(max_radius)\n        template = np.zeros((max_radius * 2 + 1, max_radius * 2 + 1), dtype=np.float32)\n        for i in range(max_radius, min_radius, -1):\n            template = cv.circle(template, (max_radius, max_radius), i, max_radius ** 2 - i ** 2, -1)\n        \n        return template * 0.1\n    \n    def __generate_linear_circle_gradient(self, min_radius, max_radius):\n        min_radius = round(min_radius)\n        max_radius = round(max_radius)\n        template = np.zeros((max_radius * 2 + 1, max_radius * 2 + 1), dtype=np.float32)\n        for i in range(max_radius, min_radius, -1):\n            print("i:", i)\n            template = cv.circle(template, (max_radius, max_radius), i, max_radius - i, -1)\n        \n        return template * 0.5\n    \n    def occupy_point(self, point_array_index):        \n        if not self.grid.arrays["walls"][point_array_index[0], point_array_index[1]]:\n            self.grid.arrays["detected_points"][point_array_index[0], point_array_index[1]] += 1\n            \n            if self.grid.arrays["detected_points"][point_array_index[0], point_array_index[1]] > self.to_boolean_threshold:\n                if not self.grid.arrays["traversed"][point_array_index[0], point_array_index[1]]:\n                    self.grid.arrays["walls"][point_array_index[0], point_array_index[1]] = True\n                    self.grid.arrays["occupied"][point_array_index[0], point_array_index[1]] = True\n                    \n\n    def mark_point_as_seen_by_lidar(self, robot_array_index, point_array_index):\n        self.grid.arrays["seen_by_lidar"] = self.__draw_bool_line(self.grid.arrays["seen_by_lidar"], robot_array_index, point_array_index)\n    \n    def __draw_bool_line(self, array, point1, point2):\n        indexes = skimage.draw.line(point1[0], point1[1], point2[0], point2[1])\n    \n        array[indexes[0][:-2], indexes[1][:-2]] = True\n        return array\n        #array = cv.line(array.astype(np.uint8), (point1[1], point1[0]), (point2[1], point2[0]), 255, thickness=1, lineType=cv.LINE_8)\n        #return array.astype(np.bool_)\n    \n    def __reset_seen_by_lidar(self):\n        self.grid.arrays["seen_by_lidar"] = np.zeros_like(self.grid.arrays["seen_by_lidar"])\n\n')
    __stickytape_write_module('mapping/floor_mapper.py', b'import numpy as np\nimport cv2 as cv\nfrom data_structures.compound_pixel_grid import CompoundExpandablePixelGrid\nfrom data_structures.angle import Angle\nimport imutils\nfrom copy import copy, deepcopy\nfrom robot.devices.camera import CameraImage\nfrom typing import List\n\nclass ColorFilter:\n    def __init__(self, lower_hsv, upper_hsv):\n        self.lower = np.array(lower_hsv)\n        self.upper = np.array(upper_hsv)\n    \n    def filter(self, img):\n        hsv_image = cv.cvtColor(img, cv.COLOR_BGR2HSV)\n        mask = cv.inRange(hsv_image, self.lower, self.upper)\n        return mask\n\nclass FloorMapper:\n    def __init__(self, pixel_grid: CompoundExpandablePixelGrid, tile_resolution, tile_size, camera_distance_from_center) -> None:\n        self.pixel_grid = pixel_grid\n        self.tile_resolution = tile_resolution\n        self.tile_size = tile_size\n        self.pixel_per_m = tile_resolution / tile_size\n        self.pov_distance_from_center = round(0.079 * self.pixel_per_m) \n        self.hole_color_filter = ColorFilter((0, 0, 10), (0, 0, 30))\n\n        tiles_up = 0\n        tiles_down = 1\n        tiles_sides = 1\n\n        min_x = self.tile_resolution * tiles_sides\n        max_x = self.tile_resolution * (tiles_sides + 1)\n        min_y = self.tile_resolution * tiles_down\n        max_y = self.tile_resolution * (tiles_down + 1)\n\n        self.center_tile_points_in_final_image = np.array(((min_x, min_y),\n                                                           (max_x, min_y),\n                                                           (max_x, max_y),\n                                                           (min_x, max_y),), dtype=np.float32)\n        \n        self.center_tile_points_in_input_image = np.array(([0, 24],  [39, 24], [32, 16], [7, 16]), dtype=np.float32)\n\n        self.flattened_image_shape = (self.tile_resolution * (tiles_sides * 2 + 1),\n                                      self.tile_resolution * (tiles_up + tiles_down + 1))\n        \n        self.final_povs_shape = (120, 120)\n        self.distance_to_center_gradient = self.__get_distance_to_center_gradient(self.final_povs_shape)\n\n    def flatten_camera_pov(self, camera_pov: np.ndarray):\n        ipm_matrix = cv.getPerspectiveTransform(self.center_tile_points_in_input_image, \n                                                self.center_tile_points_in_final_image, \n                                                solveMethod=cv.DECOMP_SVD)\n        \n        ipm = cv.warpPerspective(camera_pov, ipm_matrix, self.flattened_image_shape, flags=cv.INTER_NEAREST)\n\n        ipm = cv.resize(ipm, self.flattened_image_shape, interpolation=cv.INTER_CUBIC)\n\n        blank_space = np.zeros((self.pov_distance_from_center, self.flattened_image_shape[0], 4), dtype=np.uint8)\n        ipm = np.vstack((blank_space, ipm))\n\n        return ipm\n    \n    def set_in_background(self, pov: np.ndarray, background=None):\n        #cv.imshow(\'pov\', pov)\n        max_dim = max(pov.shape)\n        if background  is None: background = np.zeros((max_dim * 2, max_dim * 2, 4), dtype=np.uint8)\n\n        start = (max_dim, max_dim - round(pov.shape[1] / 2))\n        end =  (start[0] + pov.shape[0], start[1] + pov.shape[1])\n        \n        background[start[0]:end[0], start[1]:end[1], :] = pov[:,:,:]\n\n        #cv.imshow("pov in background", background)\n\n        return background\n    \n\n    def get_global_camera_orientations(self, robot_orientation: Angle):\n        global_camera_orientations = []\n        for camera_orientation in self.pixel_grid.camera_orientations:\n            o = camera_orientation + robot_orientation\n            o.normalize()\n            global_camera_orientations.append(o)\n        \n        return global_camera_orientations\n    \n    def rotate_image_to_angle(self, image: np.ndarray, angle: Angle):\n        return imutils.rotate(image, angle.degrees, (image.shape[0] // 2, image.shape[1] // 2))\n    \n\n    def get_unified_povs(self, camera_images: List[CameraImage]):\n        povs_list = []\n        for camera_image in camera_images:\n            pov = self.flatten_camera_pov(np.rot90(copy(camera_image.image), k=3))\n            pov = np.flip(pov, 1)\n            pov = self.set_in_background(pov)\n            pov = self.rotate_image_to_angle(pov, camera_image.data.horizontal_orientation)\n            povs_list.append(pov)\n\n        return sum(povs_list)\n    \n    def map_floor(self, camera_images, robot_grid_index):\n        povs = self.get_unified_povs(camera_images)\n\n        #cv.imshow("final_pov", povs[:, :, 3])\n\n        self.load_povs_to_grid(robot_grid_index, povs)\n\n    def load_povs_to_grid(self, robot_grid_index, povs):\n        \n        start = np.array((robot_grid_index[0] - (povs.shape[0] // 2), robot_grid_index[1] - (povs.shape[1] // 2)))\n        end = np.array((robot_grid_index[0] + (povs.shape[0] // 2), robot_grid_index[1] + (povs.shape[1] // 2)))\n\n        self.pixel_grid.expand_to_grid_index(start)\n        self.pixel_grid.expand_to_grid_index(end)\n\n        start = self.pixel_grid.grid_index_to_array_index(start)\n        end = self.pixel_grid.grid_index_to_array_index(end)\n\n        mask = povs[:,:,3] > 254\n\n        povs_gradient = np.zeros_like(self.distance_to_center_gradient)\n        povs_gradient[mask] = self.distance_to_center_gradient[mask]\n\n\n        detection_distance_mask = self.pixel_grid.arrays["floor_color_detection_distance"][start[0]:end[0], start[1]:end[1]] < povs_gradient\n\n        seen_by_camera_mask = self.pixel_grid.arrays["seen_by_camera"][start[0]:end[0], start[1]:end[1]]\n\n        final_mask = seen_by_camera_mask * detection_distance_mask\n\n        self.pixel_grid.arrays["floor_color_detection_distance"][start[0]:end[0], start[1]:end[1]][final_mask] = povs_gradient[final_mask]\n\n\n        self.pixel_grid.arrays["floor_color"][start[0]:end[0], start[1]:end[1]][final_mask] = povs[:,:,:3][final_mask]\n\n        self.detect_holes()\n\n        #self.load_average_tile_color()\n        \n    \n    def __get_distance_to_center_gradient(self, shape):\n        gradient = np.zeros(shape, dtype=np.float32)\n        for x in range(shape[0]):\n            for y in range(shape[1]):\n                gradient[x, y] = (x - shape[0] // 2) ** 2 + (y - shape[1] // 2) ** 2\n        \n        gradient = 1 - gradient / gradient.max()\n\n        return (gradient * 255).astype(np.uint8)\n    \n    def __get_offsets(self, tile_size):\n        x_offset = int(self.pixel_grid.offsets[0] % tile_size + tile_size / 2) \n        y_offset = int(self.pixel_grid.offsets[1] % tile_size + tile_size / 2)\n\n        return (x_offset, y_offset)\n    \n    def offset_array(self, array, offsets):\n        return array[offsets[0]:, offsets[1]:]\n    \n    def get_color_average_kernel(self):\n        tile_size = round(self.tile_size * self.pixel_per_m)\n        square_propotion = 0.8\n        square_size = round(tile_size * square_propotion)\n\n        kernel = np.ones((square_size, square_size), dtype=np.float32)\n\n        kernel = kernel / kernel.sum()\n\n        return kernel\n    \n    def detect_holes(self):\n        tile_size = self.tile_size * self.pixel_per_m\n        offsets = self.__get_offsets(tile_size)\n        floor_color = deepcopy(self.pixel_grid.arrays["floor_color"])\n\n        self.pixel_grid.arrays["holes"] = self.hole_color_filter.filter(self.pixel_grid.arrays["floor_color"])\n\n        self.pixel_grid.arrays["occupied"] += self.pixel_grid.arrays["holes"].astype(np.bool_)\n\n        """\n        for x in range(round(offsets[0] + tile_size / 2), floor_color.shape[0], round(tile_size)):\n            row = []\n            for y in range(round(offsets[1] + tile_size / 2), floor_color.shape[1], round(tile_size)):\n                row.append(floor_color[x, y, :])\n            image.append(row)\n\n        image = np.array(image, dtype=np.uint8)\n        """\n\n    def load_average_tile_color(self):\n        tile_size = self.tile_size * self.pixel_per_m\n        offsets = self.__get_offsets(tile_size)\n        floor_color = deepcopy(self.pixel_grid.arrays["floor_color"])\n\n        kernel = self.get_color_average_kernel()\n\n        floor_color = cv.filter2D(floor_color, -1, kernel)\n        #print("offsets", offsets)\n        image = []\n\n        for x in range(round(offsets[0] + tile_size / 2), floor_color.shape[0], round(tile_size)):\n            row = []\n            for y in range(round(offsets[1] + tile_size / 2), floor_color.shape[1], round(tile_size)):\n                row.append(floor_color[x, y, :])\n            image.append(row)\n\n        image = np.array(image, dtype=np.uint8)\n\n        \n        image = cv.resize(image, (0, 0), fx=tile_size, fy=tile_size, interpolation=cv.INTER_NEAREST)\n\n                    \n        final_x = image.shape[0] if image.shape[0] + offsets[0] < self.pixel_grid.array_shape[0] else self.pixel_grid.array_shape[0] - offsets[0]\n        final_y = image.shape[1] if image.shape[1] + offsets[1] < self.pixel_grid.array_shape[1] else self.pixel_grid.array_shape[1] - offsets[1]\n\n        #self.pixel_grid.arrays["average_floor_color"] = np.zeros((final_x, final_y, 3), dtype=np.uint8)\n\n        self.pixel_grid.arrays["average_floor_color"][offsets[0]:offsets[0] + final_x:, offsets[1]:offsets[1] + final_y, :] = image[:final_x,:final_y, :]\n        ')
    __stickytape_write_module('mapping/array_filtering.py', b'from flow_control.step_counter import StepCounter\n\nimport numpy as np\nimport cv2 as cv\n\n\nclass ArrayFilterer:\n    def __init__(self) -> None:\n        self.isolated_point_remover_kernel = np.array([[-2, -2, -2],\n                                                       [-2, 1, -2],\n                                                       [-2, -2, -2]])\n        \n        self.jagged_edge_remover_kernel = np.array([[0, -1, 0],\n                                                    [-1, 3, -1],\n                                                    [0, -1, 0]])\n        \n        self.missing_point_filler_kernel = np.array([[0, 1, 0],\n                                                    [1, 0, 1],\n                                                    [0, 1, 0]])\n        \n        self.isolated_point_step_counter = StepCounter(100)\n        self.jagged_edge_step_counter = StepCounter(100)\n        \n    def remove_isolated_points(self, array: np.ndarray) -> np.ndarray:\n        if self.isolated_point_step_counter.check():\n            isolated_points_mask = cv.filter2D(array.astype(np.uint8), -1, self.isolated_point_remover_kernel) > 0\n            array[isolated_points_mask] = False\n        self.isolated_point_step_counter.increase()\n\n    def smooth_edges(self, array: np.ndarray) -> np.ndarray:\n        if self.jagged_edge_step_counter.check():\n            int_array = array.astype(np.uint8)\n            #jagged_edge_mask = cv.filter2D(int_array, -1, self.jagged_edge_remover_kernel) > 0\n            #array[jagged_edge_mask] = False\n\n            missing_point_filler_mask = cv.filter2D(int_array, -1, self.missing_point_filler_kernel) >= 3\n            array[missing_point_filler_mask] = True\n\n        self.jagged_edge_step_counter.increase()\n\n\n')
    __stickytape_write_module('mapping/robot_mapper.py', b'import numpy as np\nimport cv2 as cv\nfrom data_structures.compound_pixel_grid import CompoundExpandablePixelGrid\nfrom data_structures.angle import Angle\nfrom data_structures.vectors import Position2D, Vector2D\nimport math\n\nclass RobotMapper:\n    def __init__(self, pixel_grid: CompoundExpandablePixelGrid, robot_diameter, pixels_per_m) -> None:\n        self.pixel_grid = pixel_grid\n        self.robot_radius = round(robot_diameter / 2 * pixels_per_m)\n        self.robot_center_radius = round(0.02 * pixels_per_m)\n\n        self.__robot_center_indexes = self.__get_circle_template_indexes(self.robot_center_radius)\n        \n        # True indexes inside the circle\n        self.__robot_diameter_indexes = self.__get_circle_template_indexes(self.robot_radius)\n\n\n        #self.__camera_pov_amplitude = Angle(30, Angle.DEGREES) # Horizontal amplitued of the fostrum of each camera\n        self.__camera_pov_amplitude = Angle(25, Angle.DEGREES) # Horizontal amplitued of the fostrum of each camera\n        self.__camera_pov_lenght = int(0.12 * 2 * pixels_per_m) # Range of each camera\n        self.__camera_orientations = (Angle(0, Angle.DEGREES), Angle(270, Angle.DEGREES), Angle(90, Angle.DEGREES)) # Orientation of the cameras\n        \n        self.__discovery_pov_amplitude =  Angle(170, Angle.DEGREES)\n        self.__discovery_pov_lenght = self.__camera_pov_lenght\n        self.__discovery_pov_orientation = Angle(0, Angle.DEGREES)\n\n    def map_traversed_by_robot(self, robot_grid_index):\n        circle = np.zeros_like(self.__robot_diameter_indexes)\n        circle[0] = self.__robot_diameter_indexes[0] + np.array(robot_grid_index)[0]\n        circle[1] = self.__robot_diameter_indexes[1] + np.array(robot_grid_index)[1]\n\n        self.pixel_grid.expand_to_grid_index((np.max(circle[0]), np.max(circle[1])))\n        self.pixel_grid.expand_to_grid_index((np.min(circle[0]), np.min(circle[1])))\n\n        robot_array_index =  self.pixel_grid.grid_index_to_array_index(robot_grid_index)[:]\n\n        circle[0] = self.__robot_diameter_indexes[0] + robot_array_index[0]\n        circle[1] = self.__robot_diameter_indexes[1] + robot_array_index[1]\n\n        self.pixel_grid.arrays["traversed"][circle[0], circle[1]] = True\n\n        self.map_traversed_by_center_of_robot(robot_grid_index)\n\n    def map_traversed_by_center_of_robot(self, robot_grid_index):\n        circle = np.zeros_like(self.__robot_center_indexes)\n        circle[0] = self.__robot_center_indexes[0] + np.array(robot_grid_index)[0]\n        circle[1] = self.__robot_center_indexes[1] + np.array(robot_grid_index)[1]\n\n        self.pixel_grid.expand_to_grid_index((np.max(circle[0]), np.max(circle[1])))\n        self.pixel_grid.expand_to_grid_index((np.min(circle[0]), np.min(circle[1])))\n\n        robot_array_index =  self.pixel_grid.grid_index_to_array_index(robot_grid_index)[:]\n\n        circle[0] = self.__robot_center_indexes[0] + robot_array_index[0]\n        circle[1] = self.__robot_center_indexes[1] + robot_array_index[1]\n\n        self.pixel_grid.arrays["robot_center_traversed"][circle[0], circle[1]] = True\n\n\n\n    def map_seen_by_camera(self, robot_grid_index, robot_rotation: Angle):\n        global_camera_orientations = []\n\n        for o in self.__camera_orientations:\n            o1 = o + robot_rotation\n            o1.normalize()\n            global_camera_orientations.append(o1)\n\n        camera_povs = self.__get_camera_povs_template_indexes(global_camera_orientations, robot_grid_index)\n\n        self.pixel_grid.expand_to_grid_index(np.array((np.max(camera_povs[0]), np.max(camera_povs[1]))))\n        self.pixel_grid.expand_to_grid_index(np.array((np.min(camera_povs[0]), np.min(camera_povs[1]))))\n\n\n        camera_povs[0] += self.pixel_grid.offsets[0]\n        camera_povs[1] += self.pixel_grid.offsets[1]\n\n        self.pixel_grid.arrays["seen_by_camera"][camera_povs[0], camera_povs[1]] += self.pixel_grid.arrays["seen_by_lidar"][camera_povs[0], camera_povs[1]]\n\n    def map_discovered_by_robot(self, robot_grid_index, robot_rotation: Angle):\n        global_discovered_orientation = self.__discovery_pov_orientation + robot_rotation\n        global_discovered_orientation.normalize()\n        \n        discovered_template = self.__get_cone_template(self.__discovery_pov_lenght, \n                                                       global_discovered_orientation, \n                                                       self.__discovery_pov_amplitude)\n        \n        disc_povs = self.__get_indexes_from_template(discovered_template, robot_grid_index - np.array((self.__discovery_pov_lenght, self.__discovery_pov_lenght)))\n        \n        self.pixel_grid.expand_to_grid_index(np.array((np.max(disc_povs[0]), np.max(disc_povs[1]))))\n        self.pixel_grid.expand_to_grid_index(np.array((np.min(disc_povs[0]), np.min(disc_povs[1]))))\n        \n        disc_povs[0] += self.pixel_grid.offsets[0]\n        disc_povs[1] += self.pixel_grid.offsets[1]\n\n        self.pixel_grid.arrays["discovered"][disc_povs[0], disc_povs[1]] += self.pixel_grid.arrays["seen_by_lidar"][disc_povs[0], disc_povs[1]]\n\n    def __get_cone_template(self, lenght, orientation: Angle, amplitude: Angle):\n        matrix_size = math.ceil(lenght) * 2\n        int_lenght = math.ceil(lenght)\n\n        matrix = np.zeros((matrix_size + 1, matrix_size + 1), np.uint8)\n\n        circle_matrix = cv.circle(np.zeros_like(matrix), (int_lenght,  int_lenght), int_lenght, 1, -1)\n        \n        center_position = Position2D(int_lenght, int_lenght)\n        \n        start_angle = orientation - (amplitude / 2)\n        start_angle.normalize()\n        start_vector = Vector2D(start_angle, lenght * 2)\n        start_position = start_vector.to_position()\n        start_position += center_position\n        start_position = (math.ceil(start_position.x), math.ceil(start_position.y))\n\n        center_angle = orientation\n        center_angle.normalize()\n        center_vector = Vector2D(center_angle, lenght * 2)\n        center_up_position = center_vector.to_position()\n        center_up_position += center_position\n        center_up_position = center_up_position.astype(int)\n\n        end_angle = orientation + (amplitude / 2)\n        end_angle.normalize()\n        end_vector = Vector2D(end_angle, lenght * 2)\n        end_position = end_vector.to_position()\n        end_position += center_position\n        end_position = (math.ceil(end_position.x), math.ceil(end_position.y))\n\n        triangle_matrix = cv.fillPoly(np.zeros_like(matrix), \n                                      [np.array([start_position, center_up_position, end_position, np.array(center_position)])],\n                                      1)\n        \n        final_matrix = triangle_matrix * circle_matrix\n\n        #cv.imshow("cone template", final_matrix * 100)\n\n        return final_matrix\n    \n    def __get_camera_povs_template_indexes(self,  camera_orientations, robot_index):\n        final_template = None\n        for orientation in camera_orientations:\n            cone_template = self.__get_cone_template(self.__camera_pov_lenght, orientation, self.__camera_pov_amplitude)\n            if final_template is None:\n                final_template = cone_template\n            else:\n                final_template += cone_template\n\n        povs_indexes = self.__get_indexes_from_template(final_template, (-self.__camera_pov_lenght + robot_index[0], -self.__camera_pov_lenght + robot_index[1]))\n\n        return povs_indexes\n\n    # Camera fostrum template generation\n    def __get_circle_template_indexes(self, radius):\n        diameter = int(radius * 2 + 1)\n\n        diameter_template = np.zeros((diameter, diameter), dtype=np.uint8)\n        diameter_template = cv.circle(diameter_template, (radius, radius), radius, 255, -1)\n        diameter_template = diameter_template.astype(np.bool_)\n\n        return self.__get_indexes_from_template(diameter_template, (-radius, -radius))\n\n    def __get_indexes_from_template(self, template: np.ndarray, offsets=(0, 0)):\n        indexes = []\n        indexes = template.nonzero()\n        indexes = np.array(indexes)\n        offsets = np.array(offsets)\n        indexes[0] += offsets[0]\n        indexes[1] += offsets[1]\n        return indexes')
    __stickytape_write_module('mapping/fixture_mapper.py', b'import math\n\nimport numpy as np\nimport cv2 as cv\n\nfrom data_structures.compound_pixel_grid import CompoundExpandablePixelGrid\n\n\nclass FixtureMapper:\n    def __init__(self, pixel_grid: CompoundExpandablePixelGrid, tile_size: float) -> None:\n        self.tile_size = tile_size\n        self.grid = pixel_grid\n\n        template_radious = int(0.05 * self.grid.resolution)\n        template_diameter = math.ceil(template_radious * 2 + 1)\n\n        # Solid disk with the radius of the fixture detection zone\n        self.fixture_detection_zone_template = np.zeros((template_diameter, template_diameter), dtype=np.int8)\n        self.fixture_detection_zone_template = cv.circle(self.fixture_detection_zone_template, (template_radious, template_radious), template_radious, 1, -1)\n\n        # Empty circle with the radius of the fixture detection zone\n        self.fixture_distance_margin_template = np.zeros((template_diameter, template_diameter), dtype=np.int8)\n        self.fixture_distance_margin_template = cv.circle(self.fixture_distance_margin_template, (template_radious, template_radious), template_radious, -50, -1)\n        self.fixture_distance_margin_template = cv.circle(self.fixture_distance_margin_template, (template_radious, template_radious), template_radious, 1, 1)\n        \n        self.detected_from_radius = round(0.02 * self.grid.resolution)\n    \n    def generate_detection_zone(self):\n        occupied_as_int = self.grid.arrays["occupied"].astype(np.int8)\n\n        #self.grid.arrays["fixture_detection_zone"] = cv.filter2D(occupied_as_int, -1, self.fixture_detection_zone_template)> 0\n\n        self.grid.arrays["fixture_distance_margin"] = cv.filter2D(occupied_as_int, -1, self.fixture_distance_margin_template) > 0\n\n        #cv.imshow("detection_template", self.fixture_detection_zone_template)\n\n    def clean_up_fixtures(self):\n        self.grid.arrays["victims"][self.grid.arrays["occupied"]] = False\n\n    def map_detected_fixture(self, robot_position):\n        robot_array_index = self.grid.coordinates_to_array_index(robot_position)\n        template = self.__get_circle_template_indexes(self.detected_from_radius, robot_array_index)\n        self.grid.arrays["robot_detected_fixture_from"][template[0], template[1]] = True\n\n    def __get_circle_template_indexes(self, radius, offsets=(0, 0)):\n        diameter = int(radius * 2 + 1)\n\n        diameter_template = np.zeros((diameter, diameter), dtype=np.uint8)\n        diameter_template = cv.circle(diameter_template, (radius, radius), radius, 255, -1)\n        diameter_template = diameter_template.astype(np.bool_)\n\n        return self.__get_indexes_from_template(diameter_template, (-radius + offsets[0], -radius + offsets[1]))\n\n    def __get_indexes_from_template(self, template: np.ndarray, offsets=(0, 0)):\n        indexes = []\n        indexes = template.nonzero()\n        indexes = np.array(indexes)\n        offsets = np.array(offsets)\n        indexes[0] += offsets[0]\n        indexes[1] += offsets[1]\n        return indexes\n')
    __stickytape_write_module('mapping/data_extractor.py', b'import numpy as np\nimport cv2 as cv\nimport copy\n\nimport utilities\n\nfrom flags import SHOW_DEBUG\n\nclass FloorColorExtractor:\n    def __init__(self, tile_resolution) -> None:\n        self.tile_resolution = tile_resolution\n        self.floor_color_ranges = {\n                    "normal":\n                        {   \n                            "range":   ((0, 0, 37), (0, 0, 192)), \n                            "threshold":0.2},\n\n                    "nothing":\n                        {\n                            "range":((100, 0, 0), (101, 1, 1)),\n                            "threshold":0.9},\n                    \n                    "checkpoint":\n                        {\n                            "range":((95, 0, 65), (128, 122, 198)),\n                            "threshold":0.2},\n                    "hole":\n                        {\n                            "range":((0, 0, 10), (0, 0, 30)),\n                            "threshold":0.2},\n                    \n                    "swamp":\n                        {\n                            "range":((19, 112, 32), (19, 141, 166)),\n                            "threshold":0.2},\n\n                    "connection1-2":\n                        {\n                            "range":((120, 182, 49), (120, 204, 232)),\n                            "threshold":0.2},\n\n                    "connection1-3":\n                        {\n                            "range":((132, 156, 36), (133, 192, 185)),\n                            "threshold":0.2},\n\n                    "connection2-3":\n                        {\n                            "range":((0, 182, 49), (0, 204, 232)),\n                            "threshold":0.2},\n                    }\n        self.final_image = np.zeros((700, 700, 3), np.uint8)\n        \n    def get_square_color(self, image, square_points):\n        square = image[square_points[0]:square_points[1], square_points[2]:square_points[3]]\n        square = cv.cvtColor(square, cv.COLOR_BGR2HSV)\n        if np.count_nonzero(square) == 0:\n            return "nothing"\n        color_counts = {}\n        for color_key, color_range in self.floor_color_ranges.items():\n            colour_count = np.count_nonzero(cv.inRange(square, color_range["range"][0], color_range["range"][1]))\n            if colour_count > color_range["threshold"] * square.shape[0] * square.shape[1]:\n                color_counts[color_key] = colour_count\n        \n        if len(color_counts) == 0:\n            return "nothing"\n        else:\n            return max(color_counts, key=color_counts.get)\n    \n    def get_sq_color(self, image, square_points):\n        square = image[square_points[0]:square_points[1], square_points[2]:square_points[3]]\n        # remove pixels with value 0, 0, 0\n        white_count = np.count_nonzero(cv.inRange(square, (180, 180, 180), (255, 255, 255)))\n        black_count = np.count_nonzero(cv.inRange(square, (20, 20, 20), (180, 180, 180)))\n\n        if white_count > black_count and white_count > square.shape[0] * square.shape[1] / 8:\n            return (255, 255, 255)\n        else:\n            return (100, 100, 100)\n\n    def get_floor_colors(self, floor_image, robot_position):\n\n        grid_offsets = [(((p + 0) % 0.06) / 0.06) * 50 for p in robot_position]\n        \n        grid_offsets = [int(o) for o in grid_offsets]\n\n        offsets = [((((p + 0.03) % 0.06) - 0.03) / 0.06) * 50 for p in robot_position]\n        \n        offsets = [int(o) for o in offsets]\n\n        \n        utilities.save_image(floor_image, "floor_image.png")\n\n        squares_grid = utilities.get_squares(floor_image, self.tile_resolution, offsets)\n\n        color_tiles = []\n        for row in squares_grid:\n            for square in row:\n                color_key = self.get_square_color(floor_image, square)\n                if color_key == "normal":\n                    color = (255, 255, 255)\n                elif color_key == "checkpoint":\n                    color = (100, 100, 100)\n                else:\n                    color = (0, 0, 0)\n                #if color != (0, 0, 0):\n                #cv.rectangle(self.final_image, [square[2], square[0]], [square[3], square[1]], color, -1)\n\n                tile = [square[2], square[0]]\n                tile = utilities.substractLists(tile, (350 - offsets[0], 350 - offsets[1]))\n                tile = utilities.divideLists(tile, [self.tile_resolution, self.tile_resolution])\n                tile = [int(t) for t in tile]\n                if color_key != "nothing":\n                    if SHOW_DEBUG:\n                        print(tile, color_key)\n                    color_tiles.append((tile, color_key))\n\n        if SHOW_DEBUG:\n            drawing_image = floor_image.copy() #self.final_image.copy()\n            utilities.draw_grid(drawing_image, self.tile_resolution, offset=grid_offsets)\n            cv.circle(drawing_image, (350 - offsets[0], 350 - offsets[1]), 10, (255, 0, 0), -1)\n            cv.imshow("final_floor_image", utilities.resize_image_to_fixed_size(drawing_image, (600, 600)))        \n        return color_tiles\n\n\n        \n        \n\nclass PointCloudExtarctor:\n    def __init__(self, resolution):\n        self.threshold = 8\n        self.resolution = resolution\n        self.straight_template = np.zeros((self.resolution + 1, self.resolution + 1), dtype=int)\n        self.straight_template[:][0:2] = 1\n        #self.straight_template[3:-3][0:2] = 2\n        self.straight_template[0][0:2] = 0\n        self.straight_template[-1][0:2] = 0\n\n        straight = [\n            [0, 1, 2, 2, 2, 1, 0],\n            [0, 1, 2, 2, 2, 1, 0],\n            [0, 0, 0, 0, 0, 0, 0],\n            [0, 0, 0, 0, 0, 0, 0],\n            [0, 0, 0, 0, 0, 0, 0],\n            [0, 0, 0, 0, 0, 0, 0],\n            [0, 0, 0, 0, 0, 0, 0],\n                ]\n        \n        self.straight_template = np.array(straight)\n\n        curved = [\n            [0, 0, 0, 0, 0, 1, 0],\n            [0, 0, 0, 1, 1, 1, 0],\n            [0, 0, 3, 1, 0, 0, 0],\n            [0, 1, 1, 0, 0, 0, 0],\n            [0, 1, 0, 0, 0, 0, 0],\n            [1, 1, 0, 0, 0, 0, 0],\n            [0, 0, 0, 0, 0, 0, 0],\n                ]\n        \n        self.curved_template = np.array(curved)\n\n\n        self.templates = {}\n\n        for i, name in enumerate([("u",), ("l",), ("d",), ("r",)]):\n            self.templates[name] = np.rot90(self.straight_template, i)\n        \n        for i, name in enumerate([("u", "l"), ("d", "l"), ("d", "r"),  ("u", "r")]):\n            self.templates[name] = np.rot90(self.curved_template, i)\n\n    def get_tile_status(self, min_x, min_y, max_x, max_y, point_cloud):\n        counts = {name: 0 for name in self.templates}\n        square = point_cloud[min_x:max_x+1, min_y:max_y+1]\n        if square.shape != (self.resolution+1, self.resolution+1):\n            return []\n\n        non_zero_indices = np.where(square != 0)\n        for name, template in self.templates.items():\n            counts[name] = np.sum(template[non_zero_indices])\n\n        names = [name for name, count in counts.items() if count >= self.threshold]\n\n        return [i for sub in names for i in sub]\n\n    def transform_to_grid(self, point_cloud):\n        offsets = point_cloud.offsets\n        offsets = [o % self.resolution for o in offsets]\n        offsets.reverse()\n        grid = []\n        bool_array_copy = point_cloud.get_bool_array()\n        if SHOW_DEBUG:\n            bool_array_copy = bool_array_copy.astype(np.uint8) * 100\n        for x in range(offsets[0], bool_array_copy.shape[0] - self.resolution, self.resolution):\n            row = []\n            for y in range(offsets[1], bool_array_copy.shape[1] - self.resolution, self.resolution):\n                min_x = x\n                min_y = y\n                max_x = x + self.resolution\n                max_y = y + self.resolution\n                #print(min_x, min_y, max_x, max_y)\n\n                if SHOW_DEBUG:\n                    bool_array_copy = cv.rectangle(bool_array_copy, (min_y, min_x), (max_y, max_x), (255,), 1)\n                \n                val = self.get_tile_status(min_x, min_y, max_x, max_y, point_cloud.get_bool_array())\n                \n                row.append(list(val))\n            grid.append(row)\n        factor = 10\n\n        if SHOW_DEBUG:\n            cv.imshow("point_cloud_with_squares", utilities.resize_image_to_fixed_size(bool_array_copy, (600, 600)))\n        offsets = point_cloud.offsets\n        return grid, [o // self.resolution for o in offsets]')
    __stickytape_write_module('fixture_detection/fixture_detection.py', b'from data_structures.vectors import Position2D, Vector2D\nfrom data_structures.angle import Angle\nfrom typing import List\nfrom robot.devices.camera import CameraImage\nfrom fixture_detection.color_filter import ColorFilter\nimport skimage\n\nimport copy\n\nimport math\n\nimport numpy as np\nimport cv2 as cv\n\nfrom data_structures.compound_pixel_grid import CompoundExpandablePixelGrid\nfrom flags import SHOW_FIXTURE_DEBUG\n\nclass FixtureDetector:\n    def __init__(self, pixel_grid: CompoundExpandablePixelGrid) -> None:\n        self.pixel_grid = pixel_grid\n\n        # Color filtering\n        self.colors = ("black", "white", "yellow", "red")\n        self.color_filters = {\n            "black": ColorFilter(lower_hsv=(0, 0, 0), upper_hsv=(0, 0, 0)),\n            "white": ColorFilter(lower_hsv=(0, 0, 207), upper_hsv=(0, 0, 207)),\n            "yellow": ColorFilter(lower_hsv=(25, 157, 82), upper_hsv=(30, 255, 255)),\n            "red": ColorFilter(lower_hsv=(160, 170, 127), upper_hsv=(170, 255, 255))\n        }\n\n        self.max_detection_distance = 0.12 * 5\n\n    def get_fixture_positions_and_angles(self, robot_position: Position2D, camera_image: CameraImage) -> list:\n        positions_in_image = self.get_fixture_positions_in_image(np.flip(camera_image.image, axis=1))\n\n        #debug = self.pixel_grid.get_colored_grid()\n\n        fixture_positions = []\n        fixture_angles = []\n        for position in positions_in_image:\n            relative_horizontal_angle = Angle(position[1] * (camera_image.data.horizontal_fov.radians / camera_image.data.width))\n\n            fixture_horizontal_angle = (relative_horizontal_angle - camera_image.data.horizontal_fov / 2) + camera_image.data.horizontal_orientation \n\n            fixture_horizontal_angle.normalize()\n\n            camera_vector = Vector2D(camera_image.data.horizontal_orientation, camera_image.data.distance_from_center)\n            camera_pos = camera_vector.to_position()\n            camera_pos += robot_position\n\n            detection_vector = Vector2D(fixture_horizontal_angle, self.max_detection_distance)\n            detection_pos = detection_vector.to_position()\n\n            detection_pos += camera_pos\n\n            camera_array_index = self.pixel_grid.coordinates_to_array_index(camera_pos)\n            detection_array_index = self.pixel_grid.coordinates_to_array_index(detection_pos)\n\n            line_xx, line_yy = skimage.draw.line(camera_array_index[0], camera_array_index[1], detection_array_index[0], detection_array_index[1])\n\n            index = 0\n            for x, y in zip(line_xx, line_yy):\n                if x >= 0 and y >= 0 and x < self.pixel_grid.array_shape[0] and y < self.pixel_grid.array_shape[1]:\n                    #debug[x, y] = (0, 255, 0)\n                    back_index = index - 2\n                    back_index = max(back_index, 0)\n                    if self.pixel_grid.arrays["walls"][x, y]:\n                        x1 = line_xx[back_index]\n                        y1 = line_yy[back_index]\n                        fixture_positions.append(self.pixel_grid.array_index_to_coordinates(np.array([x1, y1])))\n                        fixture_angles.append(copy.deepcopy(fixture_horizontal_angle))\n                        break\n                index += 1\n\n        #cv.imshow("fixture_detection_debug", debug)\n\n        return fixture_positions, fixture_angles\n    \n    def get_fixture_positions_in_image(self, image: np.ndarray) -> List[Position2D]:\n        image_sum = np.zeros(image.shape[:2], dtype=np.bool_)\n        for filter in self.color_filters.values():\n            image_sum += filter.filter(image) > 0\n\n        image_sum = image_sum.astype(np.uint8) * 255\n\n        if SHOW_FIXTURE_DEBUG:\n            cv.imshow("fixtures", image_sum)\n        \n        contours, _ = cv.findContours(image_sum, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n\n        \n        \n        final_victims = []\n        for c in contours:\n            x, y, w, h = cv.boundingRect(c)\n            final_victims.append(Position2D((x + x + w) / 2, (y + y + h) / 2))\n\n        if SHOW_FIXTURE_DEBUG:\n            debug = copy.deepcopy(image)\n            for f in final_victims:\n                debug = cv.circle(debug, np.array(f, dtype=int), 3, (255, 0, 0), -1)\n            \n            cv.imshow("victim_pos_debug", debug)\n\n        return final_victims\n    \n    def map_fixtures(self, camera_images, robot_position):\n        for i in camera_images:\n            positions, angles = self.get_fixture_positions_and_angles(robot_position, i)\n            for pos, angle in zip(positions, angles):\n                index = self.pixel_grid.coordinates_to_array_index(pos)\n                self.pixel_grid.arrays["victims"][index[0], index[1]] = True\n                self.pixel_grid.arrays["victim_angles"][index[0], index[1]] = angle.radians\n\n    def mark_reported_fixture(self, robot_position, fixture_position):\n        fixture_array_index = self.pixel_grid.coordinates_to_array_index(fixture_position)\n        rr, cc = skimage.draw.disk(fixture_array_index, 4)\n        self.pixel_grid.arrays["fixture_detection"][rr, cc] = True\n\n')
    __stickytape_write_module('fixture_detection/color_filter.py', b'import cv2 as cv\nimport numpy as np\n\nclass ColorFilter:\n    def __init__(self, lower_hsv, upper_hsv):\n        self.lower = np.array(lower_hsv)\n        self.upper = np.array(upper_hsv)\n    \n    def filter(self, img):\n        hsv_image = cv.cvtColor(img, cv.COLOR_BGR2HSV)\n        mask = cv.inRange(hsv_image, self.lower, self.upper)\n        return mask')
    __stickytape_write_module('agent/agent.py', b'from collections import namedtuple\nimport numpy as np\nfrom data_structures.vectors import Position2D\n\nfrom agent.agent_interface import AgentInterface, SubagentInterface\nfrom mapping.mapper import Mapper\n\nfrom agent.subagents.follow_walls.follow_walls_subagent import FollowWallsAgent\nfrom agent.subagents.go_to_non_discovered.go_to_non_discovered_subagent import GoToNonDiscoveredAgent\nfrom agent.subagents.return_to_start.return_to_start_subagent import ReturnToStartAgent\n\nfrom agent.pathfinding.path_time_calculator import PathTimeCalculator\n\nfrom flow_control.state_machine import StateMachine\nfrom flow_control.step_counter import StepCounter\n\n\nclass SubagentPriorityCombiner(SubagentInterface):\n    """Tries different startegies succesively until one returns a position."""\n    def __init__(self, agents: list) -> None:\n        self.__agent_list = agents\n        self.__current_agent_index = 0\n        self.__previous_agent_index = 0\n\n    def update(self, force_calculation=False) -> None:\n        agent: SubagentInterface\n        for index, agent in enumerate(self.__agent_list):\n            agent.update(force_calculation=self.__agent_changed() or force_calculation)\n            if agent.target_position_exists():\n                self.__previous_agent_index = self.__current_agent_index\n                self.__current_agent_index = index\n                break\n\n    \n    def get_target_position(self) -> Position2D:\n        return self.__agent_list[self.__current_agent_index].get_target_position()\n    \n    def target_position_exists(self) -> bool:\n        return self.__agent_list[self.__current_agent_index].target_position_exists()\n    \n    def __agent_changed(self) -> bool:\n        return self.__previous_agent_index != self.__current_agent_index\n\nclass Agent(AgentInterface):\n    def __init__(self, mapper: Mapper) -> None:\n        self.__mapper = mapper\n\n        self.__navigation_agent = SubagentPriorityCombiner([FollowWallsAgent(self.__mapper), \n                                                            GoToNonDiscoveredAgent(self.__mapper)])\n        \n        self.__return_to_start_agent = ReturnToStartAgent(self.__mapper)\n\n        self.__stage_machine = StateMachine("explore", self.__set_force_calculation)\n        self.__stage_machine.create_state(name="explore", function=self.__stage_explore, possible_changes={"return_to_start"})\n        self.__stage_machine.create_state(name="return_to_start", function=self.__stage_return_to_start)\n\n        self.do_force_calculation = False\n        self.end_reached_distance_threshold = 0.04\n        self.max_time =  8 * 60\n\n        self.__path_time_calculator_step_counter = StepCounter(300)\n        self.__path_time_calculator = PathTimeCalculator(self.__mapper, 0.06, 0.01)\n\n        self.__target_position = None\n\n    def update(self) -> None:\n        self.__stage_machine.run()\n\n    def get_target_position(self) -> Position2D:\n        return self.__target_position\n    \n    def do_end(self) -> bool:\n        return self.__stage_machine.state == "return_to_start" and \\\n               self.__mapper.robot_position.get_distance_to(self.__mapper.start_position) < self.end_reached_distance_threshold\n    \n\n    def __stage_explore(self, change_state_function):\n        self.__navigation_agent.update(force_calculation=self.do_force_calculation)\n        self.do_force_calculation = False\n\n        if not self.__navigation_agent.target_position_exists():\n            change_state_function("return_to_start")\n\n        else:\n            self.__target_position = self.__navigation_agent.get_target_position()\n\n    def __stage_return_to_start(self, _):\n        self.__return_to_start_agent.update(force_calculation=self.do_force_calculation)\n        self.do_force_calculation = False\n\n        if self.__return_to_start_agent.target_position_exists():\n            self.__target_position = self.__return_to_start_agent.get_target_position()\n        \n    \n    def __set_force_calculation(self):\n        self.do_force_calculation = True')
    __stickytape_write_module('agent/agent_interface.py', b'import random\nfrom data_structures.vectors import Position2D\nfrom abc import ABC, abstractmethod\n\nclass AgentInterface(ABC):\n    def __init__(self, mapper) -> None:\n        self.mapper = mapper\n\n    @abstractmethod\n    def update(self) -> None:\n        pass\n    \n    @abstractmethod\n    def get_target_position(self) -> Position2D:\n        pass\n\n    @abstractmethod\n    def do_end(self) -> bool:\n        pass\n\nclass SubagentInterface(ABC):\n    def __init__(self, mapper) -> None:\n        self.mapper = mapper\n\n    @abstractmethod\n    def update(self, force_calculation=False) -> None:\n        pass\n    \n    @abstractmethod\n    def get_target_position(self) -> Position2D:\n        pass\n\n    @abstractmethod\n    def target_position_exists(self) -> bool:\n        pass\n\nclass PositionFinderInterface(ABC):\n    @abstractmethod\n    def __init__(self, mapper) -> None:\n        pass\n\n    @abstractmethod\n    def update(self, force_calculation=False) -> None:\n        pass\n\n    @abstractmethod\n    def get_target_position(self) -> Position2D:\n        pass\n\n    @abstractmethod\n    def target_position_exists(self) -> bool:\n        pass')
    __stickytape_write_module('agent/subagents/follow_walls/follow_walls_subagent.py', b'import numpy as np\nfrom data_structures.vectors import Position2D\n\nfrom agent.agent_interface import SubagentInterface\nfrom mapping.mapper import Mapper\n\nfrom agent.subagents.follow_walls.follow_walls_position_finder import PositionFinder\nfrom agent.pathfinding.pathfinder import PathFinder\n\nclass FollowWallsAgent(SubagentInterface):\n    def __init__(self, mapper: Mapper) -> None:\n        self.mapper = mapper\n        self.__position_finder = PositionFinder(mapper)\n        self.__pathfinder = PathFinder(mapper)\n\n    def update(self, force_calculation=False):\n        self.__position_finder.update(force_calculation=force_calculation)\n\n        if self.__position_finder.target_position_exists():\n            target = self.__position_finder.get_target_position()\n            self.__pathfinder.update(np.array(target), force_calculation)  \n\n    def get_target_position(self) -> Position2D:\n        return self.__pathfinder.get_next_position()\n    \n    def target_position_exists(self) -> bool:\n        return self.__position_finder.target_position_exists()')
    __stickytape_write_module('agent/subagents/follow_walls/follow_walls_position_finder.py', b'import numpy as np\nfrom data_structures.vectors import Position2D\n\nfrom algorithms.np_bool_array.bfs import NavigatingBFSAlgorithm\n\nfrom agent.agent_interface import PositionFinderInterface\nfrom mapping.mapper import Mapper\n\n\nclass PositionFinder(PositionFinderInterface):\n    def __init__(self, mapper: Mapper) -> None:\n        self.__mapper = mapper\n        self.__next_position_finder = NavigatingBFSAlgorithm(lambda x: x, lambda x: not x)\n        self.__still_reachable_bfs = NavigatingBFSAlgorithm(lambda x: x, lambda x: not x)\n        self.__target = None\n\n\n    def update(self, force_calculation=False) -> None:\n        if  not self.target_position_exists() or \\\n            not self.__is_grid_index_still_reachable(self.__target) or \\\n            self.__already_passed_through_grid_index(self.__target) or \\\n            force_calculation:\n            \n            self.__calculate_position()\n\n    def get_target_position(self) -> Position2D:\n        if self.target_position_exists():\n            return self.__mapper.pixel_grid.grid_index_to_coordinates(self.__target)\n    \n    def target_position_exists(self) -> bool:\n        return self.__target is not None\n\n    def __calculate_position(self):\n        possible_targets_array = self.__mapper.pixel_grid.arrays["fixture_distance_margin"]\n        self.__dither_array(possible_targets_array, dither_interval=2)\n        possible_targets_array[self.__mapper.pixel_grid.arrays["robot_center_traversed"]] = False\n\n        #cv.imshow("possible wall targets", possible_targets_array.astype(np.uint8) * 255)\n\n        if not np.any(possible_targets_array):\n            print("no tragets")\n            return\n\n        robot_array_index = self.__mapper.pixel_grid.grid_index_to_array_index(self.__mapper.robot_grid_index)\n\n        results = self.__next_position_finder.bfs(possible_targets_array, self.__mapper.pixel_grid.arrays["traversable"], robot_array_index)\n\n        self.__target = self.__mapper.pixel_grid.array_index_to_grid_index(results[0]) if len(results) else None\n\n    \n    def __is_grid_index_still_reachable(self, grid_index) -> bool:\n        start_array_index = self.__mapper.pixel_grid.grid_index_to_array_index(grid_index)\n\n        if self.__mapper.pixel_grid.arrays["traversable"][start_array_index[0], start_array_index[1]]:\n             return False\n\n        results = self.__still_reachable_bfs.bfs(self.__mapper.pixel_grid.arrays["traversed"], self.__mapper.pixel_grid.arrays["traversable"], start_array_index)\n\n        return bool(len(results))\n    \n    def __already_passed_through_grid_index(self, grid_index):\n        array_index = self.__mapper.pixel_grid.grid_index_to_array_index(grid_index)\n\n        return self.__mapper.pixel_grid.arrays["robot_center_traversed"][array_index[0], array_index[1]]\n    \n\n    def __dither_array(self, possible_targets_array: np.ndarray, dither_interval=2):\n        mask = np.ones_like(possible_targets_array)\n\n        mask[::dither_interval, ::dither_interval] = False\n\n        mask[dither_interval//2::dither_interval, dither_interval//2::dither_interval] = False\n\n        #cv.imshow("dither_mask", (mask == False).astype(np.uint8) * 255)\n\n        possible_targets_array[mask] = False\n')
    __stickytape_write_module('algorithms/np_bool_array/bfs.py', b'import numpy as np\n\nclass BFSAlgorithm:\n    def __init__(self, found_function) -> None:\n        self.found_function = found_function\n        self.adjacents = [[0, 1], [0, -1], [-1, 0], [1, 0], ]\n\n    def get_neighbours(self, node):\n        for a in self.adjacents:\n            yield [node[0] + a[0], node[1] + a[1]]\n    \n    def bfs(self, array, start_node):\n        open_list = []\n        open_list.append(start_node)\n\n        while len(open_list) > 0:\n            node = open_list.pop(0)\n\n            value = array[node[0], node[1]]\n\n            if self.found_function(value):\n                return node\n\n            for n in self.get_neighbours(node):\n                if not n in open_list:\n                    open_list.append(n)\n\n\nclass NavigatingBFSAlgorithm:\n    def __init__(self, found_function, traversable_function, max_result_number=1) -> None:\n        self.found_function = found_function\n        self.traversable_function = traversable_function\n        self.adjacents = ((0, 1), (0, -1), (-1, 0), (1, 0))\n        self.max_result_number = max_result_number\n\n    def get_neighbours(self, node):\n        for a in self.adjacents:\n            yield (node[0] + a[0], node[1] + a[1])\n    \n    def bfs(self, found_array, traversable_array, start_node):\n        open_list = []\n        open_list.append(tuple(start_node))\n\n        closed_set = set()\n        closed_set.add(tuple(start_node))\n\n        results = []\n\n        while len(open_list) > 0:\n            node = open_list.pop(0)\n\n            if node[0] < 0 or node[1] < 0 or node[0] >= traversable_array.shape[0] or node[1] >= traversable_array.shape[1]:\n                continue\n\n            if not self.traversable_function(traversable_array[node[0], node[1]]):\n                continue\n\n            value = found_array[node[0], node[1]]\n\n            if self.found_function(value):\n                results.append(node)\n                if len(results) >= self.max_result_number:\n                    return results\n\n            for n in self.get_neighbours(node):\n                if n not in closed_set:\n                    open_list.append(n)\n                    closed_set.add(n)    \n        \n        return results\n\n')
    __stickytape_write_module('agent/pathfinding/pathfinder.py', b'import numpy as np\nimport cv2 as cv\n\nfrom data_structures.vectors import Position2D\nfrom mapping.mapper import Mapper\n\nfrom data_structures.compound_pixel_grid import CompoundExpandablePixelGrid\nfrom algorithms.np_bool_array.efficient_a_star import aStarAlgorithm\nfrom algorithms.np_bool_array.bfs import NavigatingBFSAlgorithm\n\nfrom agent.pathfinding.path_smoothing import PathSmoother\n\nfrom flags import SHOW_PATHFINDING_DEBUG, SHOW_GRANULAR_NAVIGATION_GRID\n\nclass PathFinder():\n    def __init__(self, mapper: Mapper):\n        self.__a_star = aStarAlgorithm()\n        self.__closest_free_point_finder = NavigatingBFSAlgorithm(lambda x : x == 0, lambda x: True)\n\n        self.__a_star_path_smoother = PathSmoother(1)\n\n        self.__robot_grid_index = np.array([0, 0])\n        self.__target_position = np.array([0, 0])\n\n        self.__a_star_path = []\n        self.__smooth_astar_path = []\n        self.__a_star_index = 0\n\n        self.__mapper = mapper\n\n        self.path_not_found = False\n        self.__position_changed = True\n    \n    def update(self, target_position: np.ndarray = None, force_calculation=False) -> None:\n        if target_position is not None:\n            self.__position_changed = np.any(self.__target_position != target_position)\n            self.__target_position = target_position\n\n\n\n        self.__robot_grid_index = self.__mapper.pixel_grid.coordinates_to_grid_index(self.__mapper.robot_position) # Get robot position grid index\n        self.__mapper.pixel_grid.expand_to_grid_index(self.__robot_grid_index) # Expand grid to robot position\n\n        if SHOW_PATHFINDING_DEBUG: \n            if self.is_path_finished(): print("FINISHED PATH")\n            if self.__is_path_obstructed(): print("PATH OBSTRUCTED")\n\n        if self.is_path_finished() or self.__is_path_obstructed() or self.__position_changed or force_calculation:\n            self.__calculate_path()\n            \n        self.__calculate_path_index()\n\n        #DEBUG\n        if SHOW_GRANULAR_NAVIGATION_GRID:\n            debug_grid = self.__mapper.pixel_grid.get_colored_grid()\n            for node in self.__a_star_path:\n                n = np.array(self.__mapper.pixel_grid.grid_index_to_array_index(node))\n                try:\n                    debug_grid[n[0], n[1]] = [0, 0, 255]\n                except IndexError:\n                    pass\n\n            cv.imshow("granular_grid", debug_grid)\n        \n\n\n    def __calculate_path(self):\n        # Get start array index (if robot index occupied, get closest unoccupied point)\n        start_array_index = self.__mapper.pixel_grid.coordinates_to_array_index(self.__mapper.robot_position)\n        start_array_index = self.__get_closest_traversable_array_index(start_array_index)\n\n        # Expand grid to target index\n        target_grid_index = self.__mapper.pixel_grid.coordinates_to_grid_index(self.__target_position)\n        self.__mapper.pixel_grid.expand_to_grid_index(target_grid_index)\n\n        # Get target array index (if target index occupied, get closest unoccupied point)\n        target_array_index = self.__mapper.pixel_grid.coordinates_to_array_index(self.__target_position)\n        target_array_index = self.__get_closest_traversable_array_index(target_array_index)\n\n        # Calculate path\n        best_path = self.__a_star.a_star(self.__mapper.pixel_grid.arrays["traversable"], \n                                        start_array_index,\n                                        target_array_index,\n                                        self.__mapper.pixel_grid.arrays["navigation_preference"])\n\n        # If path was successfully calculated, transform all indexes to grid indexes\n        if len(best_path) > 1:\n            self.__a_star_path = []\n            for array_index in best_path:\n                self.__a_star_path.append(self.__mapper.pixel_grid.array_index_to_grid_index(array_index))\n\n            self.__a_star_path = self.__a_star_path[1:]\n            self.__a_star_index = 0\n            self.path_not_found = False\n        else:\n            if SHOW_PATHFINDING_DEBUG: print("PATH NOT FOUND")\n            print("PATH NOT FOUND")\n            self.path_not_found = True\n        \n        self.__a_star_path = self.__dither_path(self.__a_star_path) # Remove every second positon of the path\n        self.__smooth_astar_path = self.__a_star_path_smoother.smooth(self.__a_star_path) # Smooth the path\n\n    def __calculate_path_index(self):\n        self.__a_star_index = min(self.__a_star_index, len(self.__a_star_path) - 1)   \n        if len(self.__a_star_path) > 0:\n            next_node = self.__a_star_path[self.__a_star_index]\n            next_node = Position2D(next_node)\n\n            current_grid_index = self.__mapper.pixel_grid.coordinates_to_grid_index(self.__mapper.robot_position)\n            current_node = Position2D(current_grid_index[0], current_grid_index[1])\n\n            if abs(current_node.get_distance_to(next_node)) < 3:\n                self.__a_star_index += 1\n\n    def __dither_path(self, path):\n        if not len(path):\n            return path\n        final_path = []\n        dither_interval = 2\n        for index, value in enumerate(path):\n            if index % dither_interval == 0:\n                final_path.append(value)\n        if tuple(final_path[-1]) != tuple(path[-1]):\n            final_path.append(path[-1])\n\n        if len(final_path):\n            return final_path\n        else:\n            return path\n    \n    def get_next_position(self) -> Position2D:\n        self.__a_star_index = min(self.__a_star_index, len(self.__a_star_path) -1)\n        if len(self.__smooth_astar_path):\n            pos = self.__mapper.pixel_grid.grid_index_to_coordinates(np.array(self.__smooth_astar_path[self.__a_star_index]))\n            pos = Position2D(pos[0], pos[1])\n            return pos\n        \n        else:\n            return self.__mapper.robot_position\n    \n    def __is_path_obstructed(self):\n        """\n        Is current Astar path obstructed?\n        """\n        array_index_path = []\n        for n in self.__a_star_path:\n            array_index_path.append(self.__mapper.pixel_grid.grid_index_to_array_index(n))\n            \n        for position in array_index_path:\n            if position[0] >= self.__mapper.pixel_grid.arrays["traversable"].shape[0] or \\\n               position[1] >=  self.__mapper.pixel_grid.arrays["traversable"].shape[1]:\n                continue\n\n            if position[0] < 0 or position[1] < 0:\n                continue\n\n            if self.__mapper.pixel_grid.arrays["traversable"][position[0], position[1]]:\n                return True\n            \n        return False\n    \n    def is_path_finished(self):\n        return len(self.__a_star_path) - 1 <= self.__a_star_index\n    \n\n    def __get_closest_traversable_array_index(self, array_index):\n        if self.__mapper.pixel_grid.arrays["traversable"][array_index[0], array_index[1]]:\n            return  self.__closest_free_point_finder.bfs(found_array=self.__mapper.pixel_grid.arrays["traversable"],\n                                                         traversable_array=self.__mapper.pixel_grid.arrays["traversable"],\n                                                         start_node=array_index)[0]\n        else:\n            return array_index')
    __stickytape_write_module('algorithms/np_bool_array/efficient_a_star.py', b'import numpy as np\nimport cv2 as cv\nfrom heapq import heappop, heappush\nimport math\n\n\nclass aStarNode:\n    def __init__(self, location):\n        self.location = location\n        self.parent = None\n        self.g = float(\'inf\')\n        self.p = 0\n        self.f = 0\n\n    def __gt__(self, other):  # make nodes comparable\n        return self.f > other.f\n\n    def __repr__(self):\n        return str(self.location)\n\n\nclass aStarAlgorithm:\n    def __init__(self):\n        self.adjacents = [[0, 1], [0, -1], [-1, 0], [1, 0], ]#[1, 1], [1, -1], [-1, -1], [-1, 1]]\n        #self.preference_weight = 5\n        self.preference_weight = 2\n    \n    @staticmethod\n    def reconstructpath(node):\n        path = []\n        while node is not None:\n            path.append(node.location)\n            node = node.parent\n        path.reverse()\n        return path\n\n    @staticmethod\n    def heuristic(start, target):\n        # optimistic score, assuming all cells are friendly\n        dy = abs(start[0] - target[0])\n        dx = abs(start[1] - target[1])\n        return min(dx, dy) * 15 + abs(dx - dy) * 10\n\n    @staticmethod\n    def get_preference(preference_grid, position):\n        if preference_grid is None:\n            return 0\n        elif not (position[0] >= preference_grid.shape[0] or position[1] >= preference_grid.shape[1] or position[0] < 0 or position[1] < 0):\n            return preference_grid[position[0], position[1]]\n        else:\n            return 0\n    \n    @staticmethod\n    def is_traversable(grid, position):\n        if not (position[0] >= grid.shape[0] or position[1] >= grid.shape[1] or position[0] < 0 or position[1] < 0):\n            return not grid[position[0], position[1]]\n        else:\n            return True\n\n\n        \n    # Returns a list of tuples as a path from the given start to the given end in the given maze\n    def a_star(self, grid: np.ndarray, start, end, preference_grid=None, search_limit=float(\'inf\')):\n        debug_grid = np.zeros((grid.shape[0], grid.shape[1], 3), dtype=np.uint8)\n\n        # Create start and end node\n        start_node = aStarNode(tuple(start))\n        start_node.g = 0\n        \n        if not self.is_traversable(grid, start):\n            print("WARNING: Start position is not traversable")\n\n        end_node = aStarNode(tuple(end))\n\n        if not self.is_traversable(grid, end):\n            print("WARNING: End position is not traversable")\n            return []\n\n        end_node.g = end_node.h = end_node.f = 0\n        # Initialize open and closed list\n        openList = [start_node]\n        best_cost_for_node_lookup = {tuple(start_node.location): start_node.g}\n        closed = set()\n\n        loop_n = 0\n        # Loop until end\n        while openList:            \n            # Get the current node\n            node = heappop(openList)\n            if node.location in closed:\n                continue\n\n            closed.add(node.location)\n            # If found the goal\n            if node.location == end_node.location:\n                #print(f"Finished Astar. Took {loop_n} loops.")\n                return self.reconstructpath(node)\n            \n            # Generate children\n            for adj in self.adjacents:  # Adjacent squares\n                # Get node position\n                child_location = (node.location[0] + adj[0], node.location[1] + adj[1])\n                # Make sure walkable terrain\n                if not self.is_traversable(grid, child_location):\n                    continue\n                # Create new node\n                new_child = aStarNode(child_location)\n                new_child.parent = node\n\n                new_child.g = node.g + 1\n                new_child.h =  self.heuristic(new_child.location, end_node.location)\n                \n                new_child.p = self.get_preference(preference_grid, new_child.location) * self.preference_weight\n                \n                new_child.f = new_child.g + new_child.h + new_child.p\n\n                if child_location in best_cost_for_node_lookup.keys():\n                    if new_child.g + new_child.p < best_cost_for_node_lookup[child_location]:\n                        best_cost_for_node_lookup[child_location] = new_child.g + new_child.p\n                        heappush(openList, new_child)\n                        \n                else:\n                    best_cost_for_node_lookup[child_location] = new_child.g + new_child.p\n                    heappush(openList, new_child)\n\n            loop_n += 1\n            if loop_n > search_limit:\n                break\n            \n            """\n            for o in openList:\n                debug_grid[o.location[0], o.location[1]] = [0, 0, 255]\n\n            cv.imshow("debug", debug_grid)\n\n            cv.waitKey(1)\n            """\n            \n        return []')
    __stickytape_write_module('agent/pathfinding/path_smoothing.py', b'class PathSmoother:\n    def __init__(self, strenght) -> None:\n        self.strenght = strenght\n\n    def smooth(self, path):\n        new_path = []\n        for index, node in enumerate(path):\n            prior = path[max(index - 1, 0)]\n            next = path[min(index + 1, len(path) - 1)]\n\n            avg_x = (node[0] + prior[0] * self.strenght + next[0] * self.strenght) / (1 + self.strenght * 2)\n            avg_y = (node[1] + prior[1] * self.strenght + next[1] * self.strenght) / (1 + self.strenght * 2)\n\n            new_path.append([avg_x, avg_y])\n        \n        return new_path')
    __stickytape_write_module('agent/subagents/go_to_non_discovered/go_to_non_discovered_subagent.py', b'import numpy as np\nimport cv2 as cv\n\nfrom agent.agent_interface import SubagentInterface\n\nfrom data_structures.vectors import Position2D\nfrom mapping.mapper import Mapper\n\nfrom agent.pathfinding.pathfinder import PathFinder\nfrom agent.subagents.go_to_non_discovered.go_to_non_discovered_position_finder import PositionFinder\n\nclass GoToNonDiscoveredAgent(SubagentInterface):\n    """\n    Navigates the map without any concept of \'tiles\'.\n    """\n    def __init__(self, mapper: Mapper):\n        self.__path_finder = PathFinder(mapper)\n        self.__position_finder = PositionFinder(mapper)\n    \n    def update(self, force_calculation=False) -> None:\n        self.__position_finder.update(force_calculation=self.__do_force_position_finder() or force_calculation)\n\n        if self.__position_finder.target_position_exists():\n            target = self.__position_finder.get_target_position()\n            self.__path_finder.update(target_position=np.array(target), force_calculation=force_calculation)\n\n    def get_target_position(self) -> Position2D:\n        return self.__path_finder.get_next_position()    \n    \n    def __do_force_position_finder(self) -> bool:\n        return self.__path_finder.is_path_finished() or self.__path_finder.path_not_found\n    \n    def target_position_exists(self) -> bool:\n        return self.__position_finder.target_position_exists()\n        ')
    __stickytape_write_module('agent/subagents/go_to_non_discovered/go_to_non_discovered_position_finder.py', b'from mapping.mapper import Mapper\nfrom data_structures.vectors import Position2D\nimport numpy as np\nimport cv2 as cv\n\nfrom algorithms.np_bool_array.bfs import BFSAlgorithm, NavigatingBFSAlgorithm\nfrom flags import SHOW_BEST_POSITION_FINDER_DEBUG\n\nfrom agent.agent_interface import PositionFinderInterface\n\nclass PositionFinder(PositionFinderInterface):\n    """\n    Finds the best position for the robot to go to, with the objective of exploring the maze.\n    """\n    def __init__(self, mapper: Mapper) -> None:\n        self.mapper = mapper\n        self.closest_unseen_finder = NavigatingBFSAlgorithm(found_function=lambda x: x == False, \n                                                            traversable_function=lambda x: x == False,\n                                                            max_result_number=1)\n        \n        self.closest_free_point_finder = BFSAlgorithm(lambda x : x == 0)\n        \n        self.closest_unseen_grid_index = None\n        \n\n    def update(self, force_calculation=False):\n        """\n        Calculate closest unseen position if the objective is no longer traversable or if it\'s told to do it with the \'force\' parameter.\n        """\n        if self.__is_objective_untraversable() or force_calculation:\n            self.closest_unseen_grid_index = self.__get_closest_unseen_grid_index()\n\n        # DEBUG\n        if SHOW_BEST_POSITION_FINDER_DEBUG:\n            debug_grid = self.mapper.pixel_grid.get_colored_grid()  \n            if self.target_position_exists():\n                closest_unseen_array_index = self.mapper.pixel_grid.grid_index_to_array_index(self.closest_unseen_grid_index)\n                cv.circle(debug_grid, (closest_unseen_array_index[1], closest_unseen_array_index[0]), 4, (0, 255, 100), -1)\n                cv.imshow("closest_position_finder_debug", debug_grid)\n\n    def get_target_position(self):\n        if self.target_position_exists():\n            coords = self.mapper.pixel_grid.grid_index_to_coordinates(self.closest_unseen_grid_index)\n            return Position2D(coords)\n        \n    def target_position_exists(self) -> bool:\n        return self.closest_unseen_grid_index is not None\n    \n    def __is_objective_untraversable(self):\n        if self.target_position_exists():\n            closest_unseen_array_index = self.mapper.pixel_grid.grid_index_to_array_index(self.closest_unseen_grid_index)\n            return self.mapper.pixel_grid.arrays["traversable"][closest_unseen_array_index[0], closest_unseen_array_index[1]]\n        else:\n            return False\n    \n    def __get_closest_unseen_grid_index(self):\n        robot_array_index = self.mapper.pixel_grid.coordinates_to_array_index(self.mapper.robot_position)\n        start_node = self.__get_closest_traversable_array_index(robot_array_index)\n\n        closest_unseen_array_indexes = self.closest_unseen_finder.bfs(found_array=self.mapper.pixel_grid.arrays["discovered"],\n                                                                      traversable_array=self.mapper.pixel_grid.arrays["traversable"],\n                                                                      start_node=start_node)\n        \n        if len(closest_unseen_array_indexes):\n            print("found not discovered")\n            return self.mapper.pixel_grid.array_index_to_grid_index(closest_unseen_array_indexes[0])\n        \n        else:\n            print("Ain\'t found no nothin\'")\n            return None\n\n\n    def __get_closest_traversable_array_index(self, array_index):\n        if self.mapper.pixel_grid.arrays["traversable"][array_index[0], array_index[1]]:\n            return  self.closest_free_point_finder.bfs(array=self.mapper.pixel_grid.arrays["traversable"],\n                                                       start_node=array_index)\n        else:\n            return array_index\n\n\n        \n\n\n    \n')
    __stickytape_write_module('agent/subagents/return_to_start/return_to_start_subagent.py', b'import numpy as np\n\nfrom data_structures.vectors import Position2D\n\nfrom agent.agent_interface import SubagentInterface\nfrom mapping.mapper import Mapper\n\nfrom agent.pathfinding.pathfinder import PathFinder\n\n\nclass ReturnToStartAgent(SubagentInterface):\n    def __init__(self, mapper: Mapper) -> None:\n        self.__mapper = mapper\n        self.__pathfinder = PathFinder(self.__mapper)\n\n    def update(self, force_calculation) -> None:\n        self.__pathfinder.update(np.array(self.__mapper.start_position), force_calculation=force_calculation)\n\n    def get_target_position(self) -> Position2D:\n        return self.__pathfinder.get_next_position()\n\n    def target_position_exists(self) -> bool:\n        return self.__mapper.start_position is not None')
    __stickytape_write_module('agent/pathfinding/path_time_calculator.py', b'import numpy as np\nimport cv2 as cv\n\nfrom data_structures.vectors import Position2D\nfrom mapping.mapper import Mapper\n\nfrom data_structures.compound_pixel_grid import CompoundExpandablePixelGrid\nfrom algorithms.np_bool_array.efficient_a_star import aStarAlgorithm\nfrom algorithms.np_bool_array.bfs import NavigatingBFSAlgorithm\n\nfrom flags import SHOW_PATHFINDING_DEBUG, SHOW_GRANULAR_NAVIGATION_GRID\n\nclass PathTimeCalculator():\n    def __init__(self, mapper: Mapper, factor: float, exponent: float):\n        self.__a_star = aStarAlgorithm()\n        self.__closest_free_point_finder = NavigatingBFSAlgorithm(lambda x : x == 0, lambda x: True)\n        \n        self.__mapper = mapper\n\n        self.factor = factor\n        self.exponent = exponent\n\n    \n    def calculate(self, target_position: np.ndarray):\n        n = self.__calculate_path_lenght(target_position)\n        return n * self.factor + n ** self.exponent\n\n    def __calculate_path_lenght(self, target_position):\n        \n        # Expand grid to target index\n        target_grid_index = self.__mapper.pixel_grid.coordinates_to_grid_index(target_position)\n        self.__mapper.pixel_grid.expand_to_grid_index(target_grid_index)\n\n        # Get start array index (if robot index occupied, get closest unoccupied point)\n        start_array_index = self.__mapper.pixel_grid.coordinates_to_array_index(self.__mapper.robot_position)\n        start_array_index = self.__get_closest_traversable_array_index(start_array_index)\n\n        # Get target array index (if target index occupied, get closest unoccupied point)\n        target_array_index = self.__mapper.pixel_grid.coordinates_to_array_index(target_position)\n        target_array_index = self.__get_closest_traversable_array_index(target_array_index)\n\n        # Calculate path\n        a_star_path = self.__a_star.a_star(self.__mapper.pixel_grid.arrays["traversable"], \n                                        start_array_index,\n                                        target_array_index,\n                                        self.__mapper.pixel_grid.arrays["navigation_preference"])\n        \n        \n        return len(a_star_path)\n\n\n    def __get_closest_traversable_array_index(self, array_index):\n        if self.__mapper.pixel_grid.arrays["traversable"][array_index[0], array_index[1]]:\n            return  self.__closest_free_point_finder.bfs(found_array=self.__mapper.pixel_grid.arrays["traversable"],\n                                                         traversable_array=self.__mapper.pixel_grid.arrays["traversable"],\n                                                         start_node=array_index)[0]\n        else:\n            return array_index')
    __stickytape_write_module('fixture_detection/fixture_clasification.py', b'import math\nimport random\n\nimport numpy as np\nimport cv2 as cv\n\nfrom fixture_detection.victim_clasification import VictimClassifier\nfrom fixture_detection.color_filter import ColorFilter\n\nfrom flags import SHOW_DEBUG, SHOW_FIXTURE_DEBUG\n    \nclass FixtureType:\n    def __init__(self, fixture_type, default_letter, ranges=None):\n        self.fixture_type = fixture_type\n        self.default_letter = default_letter\n        self.ranges = ranges\n    \n    def is_fixture(self, colour_counts: dict):\n        for color in self.ranges:\n            if not self.ranges[color][0] <= colour_counts[color] <= self.ranges[color][1]:\n                return False\n        return True\n            \nclass FixtureClasiffier:\n    def __init__(self):\n        # Victim classification\n        self.victim_classifier = VictimClassifier()\n\n        # Color filtering\n        self.colors = ("black", "white", "yellow", "red")\n        self.color_filters = {\n            "black": ColorFilter(lower_hsv=(0, 0, 0), upper_hsv=(0, 0, 0)),\n            "white": ColorFilter(lower_hsv=(0, 0, 207), upper_hsv=(0, 0, 207)),\n            "yellow": ColorFilter(lower_hsv=(25, 157, 82), upper_hsv=(30, 255, 255)),\n            "red": ColorFilter(lower_hsv=(160, 170, 127), upper_hsv=(170, 255, 255))\n        }\n\n        # Fixture filtering\n        #self.min_fixture_height = 10\n        #self.min_fixture_width = 19\n\n\n        self.min_fixture_height = 15\n        self.min_fixture_width = 15\n    \n        # Fixture classification\n        self.possible_fixture_letters = ["P", "O", "F", "C", "S", "H", "U"]\n\n        # In order of priority\n        self.fixture_types = (\n            FixtureType("already_detected", "",  {"white": (1,    math.inf), \n                                                  "black": (0,    0),\n                                                  "red":   (0,    0), \n                                                  "yellow":(0,    0),}),\n\n            FixtureType("flammable", "F",        {"white": (1,    math.inf), \n                                                  "red":   (1,    math.inf),}),\n\n            FixtureType("organic_peroxide", "O", {"red":   (1,    math.inf), \n                                                  "yellow":(1,    math.inf),}),\n\n            FixtureType("victim",    "H",        {"white": (4000, math.inf), \n                                                  "black": (100,  4000),}),\n\n            FixtureType("corrosive", "C",        {"white": (700,  2500), \n                                                  "black": (1000, 2500),}),\n\n            FixtureType("poison",    "P",        {"white": (700,  4000), \n                                                  "black": (0,    600),}),\n        )                    \n\n\n        # For tuning color filters\n        self.do_color_filter_tuning = False\n        self.filter_for_tuning = self.color_filters["white"]                       \n\n        if self.do_color_filter_tuning:\n            cv.namedWindow("trackbars")\n\n            cv.createTrackbar("min_h", "trackbars", self.filter_for_tuning.lower[0], 255, lambda x: None)\n            cv.createTrackbar("max_h", "trackbars", self.filter_for_tuning.upper[0], 255, lambda x: None)\n\n            cv.createTrackbar("min_s", "trackbars", self.filter_for_tuning.lower[1], 255, lambda x: None)\n            cv.createTrackbar("max_s", "trackbars", self.filter_for_tuning.upper[1], 255, lambda x: None)\n\n            cv.createTrackbar("min_v", "trackbars", self.filter_for_tuning.lower[2], 255, lambda x: None)\n            cv.createTrackbar("max_v", "trackbars", self.filter_for_tuning.upper[2], 255, lambda x: None)\n        \n    def tune_filter(self, image):\n        min_h = cv.getTrackbarPos("min_h", "trackbars")\n        max_h = cv.getTrackbarPos("max_h", "trackbars")\n        min_s = cv.getTrackbarPos("min_s", "trackbars")\n        max_s = cv.getTrackbarPos("max_s", "trackbars")\n        min_v = cv.getTrackbarPos("min_v", "trackbars")\n        max_v = cv.getTrackbarPos("max_v", "trackbars")\n        self.filter_for_tuning = ColorFilter((min_h, min_s, min_v), (max_h, max_s, max_v))\n        print(self.filter_for_tuning.lower, self.filter_for_tuning.upper)\n        cv.imshow("tunedImage", self.filter_for_tuning.filter(image))\n\n\n    def sum_images(self, images):\n        final_img = images[0]\n        for index, image in enumerate(images):\n            final_img += image\n            #cv.imshow(str(index), image)\n        final_img[final_img > 255] = 255\n        return final_img\n\n    def filter_fixtures(self, victims) -> list:\n        final_victims = []\n        for vic in victims:\n            if SHOW_FIXTURE_DEBUG:\n                print("victim:", vic["position"], vic["image"].shape)\n\n            if vic["image"].shape[0] > self.min_fixture_height and vic["image"].shape[1] > self.min_fixture_width:\n                final_victims.append(vic)\n\n        return final_victims\n\n    def find_fixtures(self, image) -> list:\n        \n        image = np.rot90(image, k=3)\n        if SHOW_FIXTURE_DEBUG:\n            cv.imshow("image", image)\n        """\n        Finds fixtures in the image.\n        Returns a list of dictionaries containing fixture positions and images.\n        """\n        binary_images = []\n        for f in self.color_filters.values():\n            binary_images.append(f.filter(image))\n\n        binary_image = self.sum_images(binary_images)\n        #print(binary_image)\n        if SHOW_FIXTURE_DEBUG:\n            cv.imshow("binaryImage", binary_image)\n        \n        # Encuentra los contornos, aunque se puede confundir con el contorno de la letra\n        contours, _ = cv.findContours(binary_image, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n        # Pra evitar la confusion dibuja rectangulos blancos donde estan los contornos en la imagen y despues vuelve a\n        # sacar los contornos para obtener solo los del rectangulo, no los de las letras.\n        for c0 in contours:\n            x, y, w, h = cv.boundingRect(c0)\n            cv.rectangle(binary_image, (x, y), (x + w, y + h), (225, 255, 255), -1)\n        contours, _ = cv.findContours(binary_image, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n        # saca las medidas y la posicion de los contornos y agrega a la lista de imagenes la parte esa de la imagen original\n        # Tambien anade la posicion de cada recuadro en la imagen original\n        final_victims = []\n        for c in contours:\n            x, y, w, h = cv.boundingRect(c)\n            final_victims.append({"image":image[y:y + h, x:x + w], "position":(x, y)})\n\n        #print("unfiltered", len(final_victims))\n        return self.filter_fixtures(final_victims)\n            \n    def count_colors(self, image) -> dict:\n        color_point_counts = {}\n\n        for name, filter in self.color_filters.items():\n            # Filter image to get specific color\n            color_image = filter.filter(image)\n\n            # Count where the mask is true\n            color_point_counts[name] = np.count_nonzero(color_image)\n\n        return color_point_counts\n\n    def classify_fixture(self, fixture) -> str:\n        image = cv.resize(fixture["image"], (100, 100), interpolation=cv.INTER_AREA)\n\n        color_point_counts = self.count_colors(image)\n        \n        if SHOW_FIXTURE_DEBUG:\n            print(color_point_counts)\n\n        # Check all filters. Find first color counts that fit.\n        final_fixture_filter = None\n        for filter in self.fixture_types:\n            if filter.is_fixture(color_point_counts):\n                final_fixture_filter = filter\n                break\n        \n        # If nothing matches return random letter\n        if final_fixture_filter is None:\n            letter = random.choice(self.possible_fixture_letters)\n\n        # If it\'s a victim classify it\n        elif final_fixture_filter.fixture_type == "victim":\n            letter = self.victim_classifier.classify_victim(fixture)\n\n        # If already detected then it shouldn\'t be reported\n        elif final_fixture_filter.fixture_type == "already_detected":\n            letter = None\n        \n        # If it\'s any other type then the letter defined for it can be returned\n        else:\n            letter = final_fixture_filter.default_letter\n\n        if SHOW_FIXTURE_DEBUG:\n            print("FIXTURE: ", letter)\n\n        return letter')
    __stickytape_write_module('fixture_detection/victim_clasification.py', b'from flags import SHOW_FIXTURE_DEBUG\nimport cv2 as cv\nimport numpy as np\nimport random\n\n\nfrom fixture_detection.color_filter import ColorFilter\n\nclass VictimClassifier:\n    def __init__(self):\n        self.white = 255\n\n        self.victim_letter_filter = ColorFilter(lower_hsv=(0, 0, 0), upper_hsv=(5, 255, 100))\n\n        self.top_image_reduction = 1\n        self.horizontal_image_reduction = 1\n\n        \n        self.area_width = 10#20\n        self.area_height = 30\n        self.min_count_in_area = int(self.area_height * self.area_width * 0.3)\n\n        """\n        self.areas = {\n            "top": ((0, self.area_height),(50 - self.area_width // 2, 50 + self.area_width // 2)),\n            "middle": ((50 - self.area_height // 2, 50 + self.area_height // 2), (50 - self.area_width // 2, 50 + self.area_width // 2)),\n            "bottom": ((100 - self.area_height, 100), (50 - self.area_width // 2, 50 + self.area_width // 2 ))\n            }\n        """\n\n        self.areas = {\n            "top": ((0, self.area_height),                                       (self.area_width // -2, self.area_width // 2)),\n            "middle": ((50 - self.area_height // 2, 50 + self.area_height // 2), (self.area_width // -2, self.area_width // 2)),\n            "bottom": ((100 - self.area_height, 100),                            (self.area_width // -2, self.area_width // 2 ))\n            }\n        \n        self.letters = {\n            "H":[{\'top\': False, \'middle\': True, \'bottom\': False}],\n            \n            "S":[{\'top\': True, \'middle\': True, \'bottom\': True},\n                 {\'top\': True, \'middle\': False, \'bottom\': True}],\n\n            "U":[{\'top\': False, \'middle\': False, \'bottom\': True}, \n                 {\'top\': False, \'middle\': False, \'bottom\': False}],\n\n            }\n\n    def crop_white(self, binaryImg):\n        white = 255\n        rows, cols = np.where(binaryImg == white)\n        if len(rows) == 0 or len(cols) == 0:\n            # no white pixels found\n            return binaryImg\n        else:\n            minY, maxY = np.min(rows), np.max(rows)\n            minX, maxX = np.min(cols), np.max(cols)\n            return binaryImg[minY:maxY+1, minX:maxX+1]\n    \n    def isolate_victim(self, image):\n        binary = self.victim_letter_filter.filter(image)\n        letter = self.crop_white(binary)\n\n        letter = letter[self.top_image_reduction:, self.horizontal_image_reduction:letter.shape[1] - self.horizontal_image_reduction]\n        letter = self.crop_white(letter)\n        \n        if SHOW_FIXTURE_DEBUG:\n            cv.imshow("thresh", binary)\n\n        return letter\n\n    def classify_victim(self, victim):\n        letter = self.isolate_victim(victim["image"])\n\n        letter = cv.resize(letter, (100, 100), interpolation=cv.INTER_AREA)\n\n        # Calculat centroid of letter and reverse it\n        moments = cv.moments(letter)\n        center = int(letter.shape[1] - moments["m10"] / moments["m00"])\n      \n        if SHOW_FIXTURE_DEBUG:\n            cv.imshow("letra", letter)\n\n        letter_color = cv.cvtColor(letter, cv.COLOR_GRAY2BGR)\n        \n        images = {\n            "top":    letter[self.areas["top"][0][0]   :self.areas["top"][0][1],    self.areas["top"][1][0]    + center:self.areas["top"][1][1]    + center],\n            "middle": letter[self.areas["middle"][0][0]:self.areas["middle"][0][1], self.areas["middle"][1][0] + center:self.areas["middle"][1][1] + center],\n            "bottom": letter[self.areas["bottom"][0][0]:self.areas["bottom"][0][1], self.areas["bottom"][1][0] + center:self.areas["bottom"][1][1] + center]\n            }\n        \n        if SHOW_FIXTURE_DEBUG:\n            cv.rectangle(letter_color,(self.areas["top"][1][0] + center, self.areas["top"][0][0]),        (self.areas["top"][1][1] + center, self.areas["top"][0][1]     ), (0, 255, 0), 1)\n            cv.rectangle(letter_color, (self.areas["middle"][1][0] + center, self.areas["middle"][0][0]), (self.areas["middle"][1][1]+ center, self.areas["middle"][0][1]), (0, 0, 255), 1)\n            cv.rectangle(letter_color,(self.areas["bottom"][1][0] + center , self.areas["bottom"][0][0]),  (self.areas["bottom"][1][1]+ center, self.areas["bottom"][0][1]), (225, 0, 255), 1)\n            cv.imshow("letter_color", letter_color)\n\n        counts = {}\n        for key in images.keys():\n            count = 0\n            for row in images[key]:\n                for pixel in row:\n                    if pixel == self.white:\n                        count += 1\n\n            counts[key] = count > self.min_count_in_area\n\n\n        for letter_key in self.letters.keys():\n            for template in self.letters[letter_key]:\n                if counts == template:\n                    print("Found:", letter_key)\n                    return letter_key\n        \n        return random.choice(list(self.letters.keys()))')
    __stickytape_write_module('final_matrix_creation/final_matrix_creator.py', b'from data_structures.compound_pixel_grid import CompoundExpandablePixelGrid\nfrom data_structures.vectors import Position2D\nimport copy\nimport math\nimport skimage\n\nimport numpy as np\nimport cv2 as cv\n\nfrom flags import SHOW_MAP_AT_END\n\nclass WallMatrixCreator:\n    def __init__(self, square_size_px: int):\n        self.threshold = 8\n        self.__square_size_px = square_size_px\n\n        straight = [\n            [0, 0, 1, 2, 2, 2, 2, 1, 0, 0],\n            [0, 0, 1, 2, 2, 2, 2, 1, 0, 0],\n            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n                ]\n        \n        self.straight_template = np.array(straight)\n\n        \n        vortex = [\n            [3, 3, 3, 0, 0, 0, 0, 0, 0, 0],\n            [3, 3, 3, 0, 0, 0, 0, 0, 0, 0],\n            [3, 3, 3, 0, 0, 0, 0, 0, 0, 0],\n            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n                ]\n        \n        self.vortex_template = np.array(vortex)\n        \n\n\n        self.templates = {}\n\n        for i, name in enumerate([(-1, 0), (0,-1), (1,0), (0,1)]):\n            self.templates[name] = np.rot90(self.straight_template, i)\n        \n        for i, name in enumerate([(-1,-1), (1, -1), (1, 1), (-1, 1)]):\n           self.templates[name] = np.rot90(self.vortex_template, i)\n\n    def __get_tile_status(self, min_x, min_y, max_x, max_y, wall_array: np.ndarray) -> list:\n        counts = {name: 0 for name in self.templates}\n        square = wall_array[min_x:max_x, min_y:max_y]\n        if square.shape != (self.__square_size_px, self.__square_size_px):\n            return []\n\n        non_zero_indices = np.where(square != 0)\n        for orientation, template in self.templates.items():\n            counts[orientation] = np.sum(template[non_zero_indices])\n\n        status = []\n        for orientation, count in counts.items():\n            if count >= self.threshold:\n                status.append(orientation)\n\n        return status\n\n    def transform_wall_array_to_bool_node_array(self, wall_array: np.ndarray, offsets: np.ndarray) -> np.ndarray:\n        grid = []\n        if SHOW_MAP_AT_END:\n            bool_array_copy = wall_array.astype(np.uint8) * 100\n        for x in range(offsets[0], wall_array.shape[0] - self.__square_size_px, self.__square_size_px):\n            row = []\n            for y in range(offsets[1], wall_array.shape[1] - self.__square_size_px, self.__square_size_px):\n                min_x = x\n                min_y = y\n                max_x = x + self.__square_size_px\n                max_y = y + self.__square_size_px\n                #print(min_x, min_y, max_x, max_y)\n                if SHOW_MAP_AT_END:\n                    bool_array_copy = cv.rectangle(bool_array_copy, (min_y, min_x), (max_y, max_x), (255,), 1)\n                \n                val = self.__get_tile_status(min_x, min_y, max_x, max_y, wall_array)\n                \n                row.append(list(val))\n            grid.append(row)\n        \n        if SHOW_MAP_AT_END:\n            cv.imshow("point_cloud_with_squares", cv.resize(bool_array_copy, (0, 0), fx=1, fy=1, interpolation=cv.INTER_AREA))\n\n        grid = self.__orientation_grid_to_final_wall_grid(grid)\n\n        return grid\n    \n    def __orientation_grid_to_final_wall_grid(self, orientation_grid: list) -> np.ndarray:\n        shape = np.array([len(orientation_grid), len(orientation_grid[0])])\n        shape *= 2\n\n        final_wall_grid = np.zeros(shape, dtype=np.bool_)\n        \n        for y, row in enumerate(orientation_grid):\n            for x, value in enumerate(row):\n                x1 = x * 2\n                y1 = y * 2\n\n                for orientation in value:\n                    final_x = x1 + orientation[1]\n                    final_y = y1 + orientation[0]\n\n                    final_wall_grid[final_y, final_x] = True\n        \n        return final_wall_grid\n    \n\nclass FloorMatrixCreator:\n    def __init__(self, square_size_px: int) -> None:\n        self.__square_size_px = square_size_px * 2\n        self.__floor_color_ranges = {\n                    "0": # Normal\n                        {   \n                            "range":   ((0, 0, 37), (0, 0, 192)), \n                            "threshold":0.2},\n\n                    "0": # Void\n                        {\n                            "range":((100, 0, 0), (101, 1, 1)),\n                            "threshold":0.9},\n                    \n                    "4": # Checkpoint\n                        {\n                            "range":((95, 0, 65), (128, 122, 198)),\n                            "threshold":0.2},\n                    "2": # Hole\n                        {\n                            "range":((0, 0, 10), (0, 0, 30)),\n                            "threshold":0.2},\n                    \n                    "3": # swamp\n                        {\n                            "range":((19, 112, 32), (19, 141, 166)),\n                            "threshold":0.2},\n\n                    "6": # Connection 1-2\n                        {\n                            "range":((120, 182, 49), (120, 204, 232)),\n                            "threshold":0.2},\n\n                    "8": # connection 3-4\n                        {\n                            "range":((132, 156, 36), (133, 192, 185)),\n                            "threshold":0.2},\n\n                    "7": # Connection2-3\n                        {\n                            "range":((0, 182, 49), (0, 204, 232)),\n                            "threshold":0.2},\n                    }\n        \n                    #TODO Add Connection 1-4\n                    \n        self.final_image = np.zeros((700, 700, 3), np.uint8)\n        \n    def __get_square_color(self, min_x, min_y, max_x, max_y, floor_array: np.ndarray) -> str:\n        square = floor_array[min_x:max_x, min_y:max_y]\n\n        square = cv.cvtColor(square, cv.COLOR_BGR2HSV)\n        \n        if np.count_nonzero(square) == 0:\n            return "0"\n        \n        color_counts = {}\n        for color_key, color_range in self.__floor_color_ranges.items():\n            colour_count = np.count_nonzero(cv.inRange(square, color_range["range"][0], color_range["range"][1]))\n            if colour_count > color_range["threshold"] * square.shape[0] * square.shape[1]:\n                color_counts[color_key] = colour_count\n        \n        if len(color_counts) == 0:\n            return "0"\n        else:\n            return max(color_counts, key=color_counts.get)\n    \n\n    def get_floor_colors(self, floor_array: np.ndarray, offsets: np.ndarray) -> np.ndarray:\n\n        if SHOW_MAP_AT_END:\n            array_copy = copy.deepcopy(floor_array)\n\n        grid = []\n\n        for x in range(offsets[0], floor_array.shape[0] - self.__square_size_px, self.__square_size_px):\n            row = []\n            for y in range(offsets[1], floor_array.shape[1] - self.__square_size_px, self.__square_size_px):\n                min_x = x\n                min_y = y\n                max_x = x + self.__square_size_px\n                max_y = y + self.__square_size_px\n                \n                if SHOW_MAP_AT_END:\n                    array_copy = cv.rectangle(array_copy, (min_y, min_x), (max_y, max_x), (255, 255, 255), 1)\n                \n                color_key = self.__get_square_color(min_x, min_y, max_x, max_y, floor_array)\n\n                row.append(color_key)\n            grid.append(row)\n\n        if SHOW_MAP_AT_END:\n            cv.imshow("array copy", array_copy)\n\n        return grid\n        \n\nclass FinalMatrixCreator:\n    def __init__(self, tile_size: float, resolution: float):\n        self.__square_size_px = round(tile_size / 2 * resolution)\n\n        self.wall_matrix_creator = WallMatrixCreator(self.__square_size_px)\n        self.floor_matrix_creator = FloorMatrixCreator(self.__square_size_px)\n\n\n    def pixel_grid_to_final_grid(self, pixel_grid: CompoundExpandablePixelGrid, robot_start_position: np.ndarray) -> np.ndarray:\n        np.set_printoptions(linewidth=1000000000000, threshold=100000000000000)\n        wall_array = pixel_grid.arrays["walls"]\n        color_array = pixel_grid.arrays["floor_color"]\n\n        offsets = self.__get_offsets(self.__square_size_px, pixel_grid.offsets)\n        \n        # Walls\n        wall_node_array = self.wall_matrix_creator.transform_wall_array_to_bool_node_array(wall_array, offsets)\n\n\n        floor_offsets = self.__get_offsets(self.__square_size_px * 2, pixel_grid.offsets + self.__square_size_px)\n\n        # Floor\n        floor_string_array = self.floor_matrix_creator.get_floor_colors(color_array, floor_offsets)\n\n        # Start tile\n        if robot_start_position is None:\n            return np.array([])\n        \n        start_array_index = pixel_grid.coordinates_to_array_index(robot_start_position)\n        start_array_index -= offsets\n        robot_node = np.round((start_array_index / self.__square_size_px) * 2).astype(int) - 1\n\n\n        # Mix everything togehter\n        text_grid = self.__get_final_text_grid(wall_node_array, floor_string_array, robot_node)\n\n\n        return np.array(text_grid)\n\n        #wall_array = self.offset_array(wall_array, self.square_size_px, pixel_grid.offsets)\n        #color_array = self.offset_array(color_array, self.square_size_px, pixel_grid.offsets)\n\n    def __get_final_text_grid(self, wall_node_array: np.ndarray, floor_type_array: np.ndarray, robot_node: np.ndarray) -> list:\n        if SHOW_MAP_AT_END:\n            cv.imshow("final_grid", cv.resize(wall_node_array.astype(np.uint8) * 255, (0, 0), fx=10, fy=10, interpolation=cv.INTER_AREA))\n        \n        final_text_grid = []\n\n        # set walls\n        for row in wall_node_array:\n            f_row = []\n            for val in row:\n                if val:\n                    f_row.append("1")\n                else:\n                    f_row.append("0")\n            final_text_grid.append(f_row)\n\n        #set floor\n        for y, row in enumerate(floor_type_array):\n            for x, val in enumerate(row):\n                x1 = x * 4 + 3\n                y1 = y * 4 + 3\n                self.__set_node_as_character(final_text_grid, np.array([y1, x1]), val)\n\n        \n        self.__set_node_as_character(final_text_grid, robot_node, "5")\n\n        return final_text_grid\n        \n    \n    def __get_offsets(self, square_size: float, raw_offsets: np.array) -> np.ndarray:\n        return np.round(raw_offsets % square_size).astype(int)\n    \n\n    def __set_node_as_character(self, final_text_grid: list, node: np.ndarray, character: str) -> list:\n        for diagonal in np.array(((1, 1), (-1, 1), (-1, -1), (1, -1))):\n            n = node + diagonal\n            try:\n                final_text_grid[n[0]][n[1]] = character\n            except IndexError:\n                pass\n\n        return final_text_grid\n\n')
    from executor.executor import Executor
    from mapping.mapper import Mapper
    from robot.robot import Robot
    
    def main():
        robot = Robot(time_step=32)
        mapper = Mapper(tile_size=0.12, robot_diameter=robot.diameter, camera_distance_from_center=robot.diameter / 2)
        executor = Executor(mapper, robot)
    
        executor.run()
    
    
    main()